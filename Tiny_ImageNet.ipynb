{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Tiny ImageNet.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "_6wtxsmX1sy0"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.python.keras.layers import (Flatten,LeakyReLU,AveragePooling2D,concatenate,\n",
        "                                            Reshape,Activation, Conv2D, Input, MaxPooling2D,\n",
        "                                            BatchNormalization, Lambda,SeparableConv2D,GlobalAveragePooling2D)\n",
        "def resNetBlock(input_image):\n",
        "\n",
        "  layer1 = SeparableConv2D(512, 3, strides=(1,1), padding='same', use_bias=False)(input_image)\n",
        "  layer1 = BatchNormalization()(layer1)\n",
        "  layer1 = LeakyReLU(alpha=0.1)(layer1)\n",
        "  \n",
        "  layer2 = SeparableConv2D(1024, 3, strides=(1,1), padding='same', use_bias=False)(layer1)\n",
        "  layer2 = BatchNormalization()(layer2)\n",
        "  layer2 = LeakyReLU(alpha=0.1)(layer2)\n",
        "  \n",
        "  layer3 = SeparableConv2D(256,3, strides=(1,1), padding='same', use_bias=False)(layer2)\n",
        "  layer3 = BatchNormalization()(layer3)\n",
        "  \n",
        "  return layer3  \n",
        "\n",
        "def build_model(img_size):\n",
        "  input_shape = Input(shape=(img_size,img_size,3)) \n",
        "\n",
        "  layer_1 = SeparableConv2D(64, 3, strides=(1,1), padding='same', use_bias=False)(input_shape)\n",
        "  layer_1 = BatchNormalization()(layer_1)\n",
        "  layer_1 = LeakyReLU(alpha=0.1)(layer_1)\n",
        "  \n",
        "  layer_2 = SeparableConv2D(128, 3, strides=(1,1), padding='same', use_bias=False)(layer_1)\n",
        "  layer_2 = BatchNormalization()(layer_2)\n",
        "  layer_2 = LeakyReLU(alpha=0.1)(layer_2)\n",
        "  \n",
        "  layer_3 = SeparableConv2D(256, 3, strides=(1,1), padding='same', use_bias=False)(layer_2)\n",
        "  layer_3 = BatchNormalization()(layer_3)\n",
        "  layer_3 = LeakyReLU(alpha=0.1)(layer_3)\n",
        " \n",
        "  resNetBlock1 = resNetBlock(layer_3)\n",
        "  concact1 = concatenate([resNetBlock1, layer_3])\n",
        "  layer_l = LeakyReLU(alpha=0.1)(concact1)\n",
        "  maxpool1 = MaxPooling2D(pool_size=(2, 2))(layer_l)\n",
        "\n",
        "  resNetBlock2 = resNetBlock(maxpool1)\n",
        "  concact2 = concatenate([resNetBlock2, maxpool1])\n",
        "  layer_l2 = LeakyReLU(alpha=0.1)(concact2)\n",
        "  maxpool2 = MaxPooling2D(pool_size=(2, 2))(layer_l2)\n",
        "\n",
        "  layer_z = SeparableConv2D(1024, 3, strides=(1,1), padding='same', use_bias=False)(maxpool1)\n",
        "  layer_z = BatchNormalization()(layer_z)\n",
        "  maxpool3 = MaxPooling2D(pool_size=(2, 2))(layer_z)\n",
        "\n",
        "  resNetBlock3 = resNetBlock(maxpool2)\n",
        "  concact3 = concatenate([resNetBlock3, maxpool2])\n",
        "  concact4 = concatenate([concact3, maxpool3])\n",
        "  layer_l3 = LeakyReLU(alpha=0.1)(concact4)\n",
        "\n",
        "  layer_ant = Conv2D(200, (1,1), strides=(1,1), padding='same', use_bias=False)(layer_l3)\n",
        "  global_avg = GlobalAveragePooling2D()(layer_ant)\n",
        "\n",
        "  output = Activation('softmax')(global_avg)\n",
        "\n",
        "  model = tf.keras.Model(inputs=input_shape, outputs=output)\n",
        "\n",
        "  return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ktOuGRz8wick"
      },
      "source": [
        "import os\n",
        "import zipfile\n",
        "\n",
        "ZIP_FILE = 'tiny-imagenet-200.zip'\n",
        "INPUT_DATA_FOLDER= 'tiny-imagenet-200'\n",
        "\n",
        "def extract_images():\n",
        "    \n",
        "    files = os.listdir('./')\n",
        "    \n",
        "    if ZIP_FILE not in files:\n",
        "      os.system('wget http://cs231n.stanford.edu/tiny-imagenet-200.zip')\n",
        "    if INPUT_DATA_FOLDER not in files:\n",
        "      zip_ref = zipfile.ZipFile('tiny-imagenet-200.zip')\n",
        "      zip_ref.extractall('./')\n",
        "      zip_ref.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ybzkohohv0NO",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "284bcb30-184c-4b76-e5db-ef3480f65a17"
      },
      "source": [
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "train_datagen = ImageDataGenerator(rescale=1./255,\n",
        "                                   brightness_range=(0.5,1.5),\n",
        "                                   rotation_range=45,\n",
        "                                   zoom_range=0.2,\n",
        "                                   shear_range=0.2,\n",
        "                                   width_shift_range=0.2,\n",
        "                                   height_shift_range=0.2,\n",
        "                                   horizontal_flip=True,\n",
        "                                   fill_mode='nearest')\n",
        "\n",
        "valid_datagen = ImageDataGenerator(rescale=1./255)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Djh3z4McP4IE"
      },
      "source": [
        "import os\n",
        "\n",
        "SAVED_MODEL = 'vddddAssignment4Amodel'\n",
        "\n",
        "def fetch_model(input_size):\n",
        "  files = os.listdir('/gdrive/My Drive/tpuweights/')\n",
        "\n",
        "  matchs = [s for s in files if SAVED_MODEL in s]\n",
        "  \n",
        "  least_val_loss = 1000.00\n",
        "  previous_model_file = ''\n",
        "  for m in matchs:\n",
        "      if float((m.split('_',2)[2]).split('.hdf5',1)[0]) < least_val_loss:\n",
        "        least_val_loss = float((m.split('_',2)[2]).split('.hdf5',1)[0])\n",
        "        previous_model_file = '/gdrive/My Drive/tpuweights/' + m\n",
        "  if(least_val_loss < 1000.00):\n",
        "      print(\"Loading previous model with least val loss: \"+ str(previous_model_file))\n",
        "      current_model = build_model(img_size=input_size)\n",
        "      current_model.load_weights(previous_model_file)\n",
        "  else:\n",
        "      print(\"No previous model..   creating new Model\")\n",
        "      current_model = build_model(img_size=input_size)\n",
        "  \n",
        "  return current_model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zdp_ftEKudql",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        },
        "outputId": "b080c90d-1786-4edf-da45-09cd35eb96c1"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "extract_images()\n",
        "\n",
        "val_data = pd.read_csv('./tiny-imagenet-200/val/val_annotations.txt', sep='\\t', header=None, names=['File', 'Class', 'X', 'Y', 'H', 'W'])\n",
        "val_data.drop(['X', 'Y', 'H', 'W'], axis=1, inplace=True)\n",
        "val_data.head(3)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>File</th>\n",
              "      <th>Class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>val_0.JPEG</td>\n",
              "      <td>n03444034</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>val_1.JPEG</td>\n",
              "      <td>n04067472</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>val_2.JPEG</td>\n",
              "      <td>n04070727</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         File      Class\n",
              "0  val_0.JPEG  n03444034\n",
              "1  val_1.JPEG  n04067472\n",
              "2  val_2.JPEG  n04070727"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sVQ50vkfhSQ3"
      },
      "source": [
        "from PIL import Image,ImageOps,ImageFilter\n",
        "import numpy as np\n",
        "from skimage.util import random_noise\n",
        "import random\n",
        "\n",
        "def additional_augmentation(batch):\n",
        "  while True:\n",
        "    batch_x, batch_y = next(batch)\n",
        "    imageshape = batch_x.shape[1]\n",
        "    final_batch_x_imgs = np.zeros((batch_x.shape[0], imageshape, imageshape, 3))\n",
        "    for i in range(batch_x.shape[0]):\n",
        "      pil_image = Image.fromarray((batch_x[i] * 255).astype('uint8'),mode='RGB')\n",
        "      index = random.randint(0,25)\n",
        "      if(index==0 or index > 14):\n",
        "        final_batch_x_imgs[i] = batch_x[i]\n",
        "        \n",
        "      if(index==1 and imageshape >= 32):\n",
        "        final_batch_x_imgs[i] = random_crops(pil_image,imageshape)\n",
        "      if(index==2):\n",
        "        final_batch_x_imgs[i] = randomnoise(batch_x[i],imageshape)\n",
        "      if(index==3):\n",
        "        final_batch_x_imgs[i] = autocontrast(pil_image,imageshape)\n",
        "      if(index==4):\n",
        "        final_batch_x_imgs[i] = equalize(pil_image,imageshape)\n",
        "      if(index==5):\n",
        "        final_batch_x_imgs[i] = blur(pil_image,imageshape)\n",
        "      if(index==6):\n",
        "        final_batch_x_imgs[i] = contour(pil_image,imageshape)\n",
        "      if(index==7):\n",
        "        final_batch_x_imgs[i] = detail(pil_image,imageshape)\n",
        "      if(index==8):\n",
        "        final_batch_x_imgs[i] = edge_enhance(pil_image,imageshape)\n",
        "      if(index==9):\n",
        "        final_batch_x_imgs[i] = edge_enhance_more(pil_image,imageshape)\n",
        "      if(index==10):\n",
        "        final_batch_x_imgs[i] = emboss(pil_image,imageshape)\n",
        "      if(index==11):\n",
        "        final_batch_x_imgs[i] = FIND_EDGES(pil_image,imageshape)\n",
        "      if(index==12):\n",
        "        final_batch_x_imgs[i] = SHARPEN(pil_image,imageshape)\n",
        "      if(index==13):\n",
        "        final_batch_x_imgs[i] = SMOOTH(pil_image,imageshape)\n",
        "      if(index==14):\n",
        "        final_batch_x_imgs[i] = SMOOTH_MORE(pil_image,imageshape)\n",
        "\n",
        "      if(np.isnan(final_batch_x_imgs[i] ).any()):\n",
        "        final_batch_x_imgs[i] = batch_x[i]\n",
        "        \n",
        "    yield (final_batch_x_imgs,batch_y)\n",
        "    \n",
        "# Resize Image \n",
        "def resize(image,currentsize):\n",
        "  resized_img = np.zeros((currentsize, currentsize, 3))\n",
        "  im2 = image.resize((currentsize, currentsize), Image.NEAREST)  \n",
        "  resized_img = (np.array(im2.getdata()).reshape(currentsize, currentsize, 3))/255\n",
        "  return resized_img\n",
        "\n",
        "# Random Crop\n",
        "def random_crops(image,currentsize):\n",
        "  crop_size=0\n",
        "  if(currentsize == 64):\n",
        "    crop_size = 45\n",
        "  if(currentsize == 32):\n",
        "    crop_size = 25\n",
        "  if(currentsize == 48):\n",
        "    crop_size = 35\n",
        "  height = np.random.randint(0, currentsize - crop_size + 1)\n",
        "  im4 = image.crop((height,height, height+crop_size,height+crop_size))\n",
        "  return resize(im4,currentsize)\n",
        "\n",
        "# Random Noise\n",
        "def randomnoise(image,currentsize):\n",
        "  return random_noise(image)\n",
        "   \n",
        "#autocontrast\n",
        "def autocontrast(image,currentsize):\n",
        "  temp_img = np.zeros((currentsize, currentsize, 3))\n",
        "  im2 = ImageOps.autocontrast(image)\n",
        "  temp_img = (np.array(im2.getdata()).reshape(currentsize, currentsize, 3))/255\n",
        "  return temp_img\n",
        "  \n",
        "#equalize\n",
        "def equalize(image,currentsize):\n",
        "  temp_img = np.zeros((currentsize, currentsize, 3))\n",
        "  im2 = ImageOps.equalize(image)\n",
        "  temp_img = (np.array(im2.getdata()).reshape(currentsize, currentsize, 3))/255\n",
        "  return temp_img\n",
        "  \n",
        "#BLUR\n",
        "def blur(image,currentsize):\n",
        "  temp_img = np.zeros((currentsize, currentsize, 3))\n",
        "  im2 = image.filter(ImageFilter.BLUR)\n",
        "  temp_img = (np.array(im2.getdata()).reshape(currentsize, currentsize, 3))/255\n",
        "  return temp_img\n",
        "\n",
        "#CONTOUR\n",
        "def contour(image,currentsize):\n",
        "  temp_img = np.zeros((currentsize, currentsize, 3))\n",
        "  im2 = image.filter(ImageFilter.CONTOUR)\n",
        "  temp_img = (np.array(im2.getdata()).reshape(currentsize, currentsize, 3))/255\n",
        "  return temp_img\n",
        "\n",
        "#DETAIL\n",
        "def detail(image,currentsize):\n",
        "  temp_img = np.zeros((currentsize, currentsize, 3))\n",
        "  im2 = image.filter(ImageFilter.DETAIL)\n",
        "  temp_img = (np.array(im2.getdata()).reshape(currentsize, currentsize, 3))/255\n",
        "  return temp_img\n",
        "\n",
        "#EDGE_ENHANCE\n",
        "def edge_enhance(image,currentsize):\n",
        "  temp_img = np.zeros((currentsize, currentsize, 3))\n",
        "  im2 = image.filter(ImageFilter.EDGE_ENHANCE)\n",
        "  temp_img = (np.array(im2.getdata()).reshape(currentsize, currentsize, 3))/255\n",
        "  return temp_img\n",
        "\n",
        "#EDGE_ENHANCE_MORE\n",
        "def edge_enhance_more(image,currentsize):\n",
        "  temp_img = np.zeros((currentsize, currentsize, 3))\n",
        "  im2 = image.filter(ImageFilter.EDGE_ENHANCE_MORE)\n",
        "  temp_img = (np.array(im2.getdata()).reshape(currentsize, currentsize, 3))/255\n",
        "  return temp_img\n",
        "\n",
        "#EMBOSS\n",
        "def emboss(image,currentsize):\n",
        "  temp_img = np.zeros((currentsize, currentsize, 3))\n",
        "  im2 = image.filter(ImageFilter.EMBOSS)\n",
        "  temp_img = (np.array(im2.getdata()).reshape(currentsize, currentsize, 3))/255\n",
        "  return temp_img\n",
        "\n",
        "#FIND_EDGES\n",
        "def FIND_EDGES(image,currentsize):\n",
        "  temp_img = np.zeros((currentsize, currentsize, 3))\n",
        "  im2 = image.filter(ImageFilter.FIND_EDGES)\n",
        "  temp_img = (np.array(im2.getdata()).reshape(currentsize, currentsize, 3))/255\n",
        "  return temp_img\n",
        "\n",
        "#SHARPEN\n",
        "def SHARPEN(image,currentsize):\n",
        "  temp_img = np.zeros((currentsize, currentsize, 3))\n",
        "  im2 = image.filter(ImageFilter.SHARPEN)\n",
        "  temp_img = (np.array(im2.getdata()).reshape(currentsize, currentsize, 3))/255\n",
        "  return temp_img\n",
        "\n",
        "#SMOOTH\n",
        "def SMOOTH(image,currentsize):\n",
        "  temp_img = np.zeros((currentsize, currentsize, 3))\n",
        "  im2 = image.filter(ImageFilter.SMOOTH)\n",
        "  temp_img = (np.array(im2.getdata()).reshape(currentsize, currentsize, 3))/255\n",
        "  return temp_img\n",
        "\n",
        "#SMOOTH_MORE\n",
        "def SMOOTH_MORE(image,currentsize):\n",
        "  temp_img = np.zeros((currentsize, currentsize, 3))\n",
        "  im2 = image.filter(ImageFilter.SMOOTH_MORE)\n",
        "  temp_img = (np.array(im2.getdata()).reshape(currentsize, currentsize, 3))/255\n",
        "  return temp_img"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PQwnGfkoJmMx",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 126
        },
        "outputId": "578362e9-da61-4d33-be17-fba1d52456bd"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/gdrive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eWFMj_B9XBuO"
      },
      "source": [
        "from tensorflow.python.keras.callbacks import ModelCheckpoint\n",
        "import numpy as np\n",
        "\n",
        "def learning_strategy(image_size,previous_epoch,epoch_size,batchsize,learning_rate):\n",
        "  \n",
        "  tf.keras.backend.clear_session()\n",
        "  TPU_WORKER = 'grpc://' + os.environ['COLAB_TPU_ADDR']\n",
        "  \n",
        "  modelx = fetch_model(image_size)\n",
        "  modelx.compile(loss='categorical_crossentropy',optimizer=tf.train.AdamOptimizer(learning_rate=learning_rate),metrics=['accuracy'])\n",
        "  \n",
        "  model_tpu = tf.contrib.tpu.keras_to_tpu_model(modelx,strategy=tf.contrib.tpu.TPUDistributionStrategy(tf.contrib.cluster_resolver.TPUClusterResolver(tpu=TPU_WORKER)))\n",
        "  model_tpu.summary()\n",
        "  \n",
        "  train_generator = train_datagen.flow_from_directory( r'./tiny-imagenet-200/train/', target_size=(image_size,image_size),color_mode='rgb',batch_size=batchsize, class_mode='categorical', shuffle=True, seed=42)\n",
        "\n",
        "  validation_generator = valid_datagen.flow_from_dataframe(val_data, directory='./tiny-imagenet-200/val/images/', x_col='File', y_col='Class', target_size=(image_size,image_size),\n",
        "                                                    color_mode='rgb', class_mode='categorical', batch_size=batchsize, shuffle=True, seed=42)\n",
        "\n",
        "  checkpoint = ModelCheckpoint('/gdrive/My Drive/tpuweights/vddddAssignment4Amodel_{epoch:02d}_{val_loss:.2f}.hdf5',monitor='val_acc',save_weights_only=True,save_best_only = True,mode='auto')\n",
        "  model_tpu.fit_generator(additional_augmentation(train_generator),initial_epoch=previous_epoch,epochs=epoch_size,steps_per_epoch=int(100000/batchsize),verbose=1,validation_data=validation_generator,validation_steps=int(10000/batchsize),callbacks=[checkpoint])                       "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7JNM61KNh-Kk",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 6010
        },
        "outputId": "dfe7d200-b32c-4058-dd2f-1b0a3ad7ad6a"
      },
      "source": [
        "learning_strategy(image_size=32,previous_epoch=0,epoch_size=50,batchsize=1024,learning_rate=0.001)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[]\n",
            "0\n",
            "No previous model..   creating new Model\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n",
            "\n",
            "WARNING: The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
            "For more information, please see:\n",
            "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
            "  * https://github.com/tensorflow/addons\n",
            "If you depend on functionality not listed there, please file an issue.\n",
            "\n",
            "INFO:tensorflow:Querying Tensorflow master (grpc://10.83.166.114:8470) for TPU system metadata.\n",
            "INFO:tensorflow:Found TPU system:\n",
            "INFO:tensorflow:*** Num TPU Cores: 8\n",
            "INFO:tensorflow:*** Num TPU Workers: 1\n",
            "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, -1, 13500332730615543303)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 17179869184, 10911548605046438221)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 17179869184, 13310310715681238334)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 17179869184, 13603759284196199019)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 17179869184, 13271506822373635801)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 17179869184, 12865063715420442997)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 17179869184, 695705940928788856)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 17179869184, 11427421158650622169)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 17179869184, 17740846334454896448)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 17179869184, 13627862481255270662)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 17179869184, 12438717959147637322)\n",
            "WARNING:tensorflow:tpu_model (from tensorflow.contrib.tpu.python.tpu.keras_support) is experimental and may change or be removed at any time, and without warning.\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            (None, 32, 32, 3)    0                                            \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d (SeparableConv (None, 32, 32, 64)   219         input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1 (BatchNo (None, 32, 32, 64)   256         separable_conv2d[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu (LeakyReLU)         (None, 32, 32, 64)   0           batch_normalization_v1[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_1 (SeparableCo (None, 32, 32, 128)  8768        leaky_re_lu[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_1 (Batch (None, 32, 32, 128)  512         separable_conv2d_1[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_1 (LeakyReLU)       (None, 32, 32, 128)  0           batch_normalization_v1_1[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_2 (SeparableCo (None, 32, 32, 256)  33920       leaky_re_lu_1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_2 (Batch (None, 32, 32, 256)  1024        separable_conv2d_2[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_2 (LeakyReLU)       (None, 32, 32, 256)  0           batch_normalization_v1_2[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_3 (SeparableCo (None, 32, 32, 512)  133376      leaky_re_lu_2[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_3 (Batch (None, 32, 32, 512)  2048        separable_conv2d_3[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_3 (LeakyReLU)       (None, 32, 32, 512)  0           batch_normalization_v1_3[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_4 (SeparableCo (None, 32, 32, 1024) 528896      leaky_re_lu_3[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_4 (Batch (None, 32, 32, 1024) 4096        separable_conv2d_4[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_4 (LeakyReLU)       (None, 32, 32, 1024) 0           batch_normalization_v1_4[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_5 (SeparableCo (None, 32, 32, 256)  271360      leaky_re_lu_4[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_5 (Batch (None, 32, 32, 256)  1024        separable_conv2d_5[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "concatenate (Concatenate)       (None, 32, 32, 512)  0           batch_normalization_v1_5[0][0]   \n",
            "                                                                 leaky_re_lu_2[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_5 (LeakyReLU)       (None, 32, 32, 512)  0           concatenate[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D)    (None, 16, 16, 512)  0           leaky_re_lu_5[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_6 (SeparableCo (None, 16, 16, 512)  266752      max_pooling2d[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_6 (Batch (None, 16, 16, 512)  2048        separable_conv2d_6[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_6 (LeakyReLU)       (None, 16, 16, 512)  0           batch_normalization_v1_6[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_7 (SeparableCo (None, 16, 16, 1024) 528896      leaky_re_lu_6[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_7 (Batch (None, 16, 16, 1024) 4096        separable_conv2d_7[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_7 (LeakyReLU)       (None, 16, 16, 1024) 0           batch_normalization_v1_7[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_8 (SeparableCo (None, 16, 16, 256)  271360      leaky_re_lu_7[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_8 (Batch (None, 16, 16, 256)  1024        separable_conv2d_8[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_1 (Concatenate)     (None, 16, 16, 768)  0           batch_normalization_v1_8[0][0]   \n",
            "                                                                 max_pooling2d[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_8 (LeakyReLU)       (None, 16, 16, 768)  0           concatenate_1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2D)  (None, 8, 8, 768)    0           leaky_re_lu_8[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_10 (SeparableC (None, 8, 8, 512)    400128      max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_10 (Batc (None, 8, 8, 512)    2048        separable_conv2d_10[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_9 (LeakyReLU)       (None, 8, 8, 512)    0           batch_normalization_v1_10[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_11 (SeparableC (None, 8, 8, 1024)   528896      leaky_re_lu_9[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_11 (Batc (None, 8, 8, 1024)   4096        separable_conv2d_11[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_10 (LeakyReLU)      (None, 8, 8, 1024)   0           batch_normalization_v1_11[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_12 (SeparableC (None, 8, 8, 256)    271360      leaky_re_lu_10[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_9 (SeparableCo (None, 16, 16, 1024) 528896      max_pooling2d[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_12 (Batc (None, 8, 8, 256)    1024        separable_conv2d_12[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_9 (Batch (None, 16, 16, 1024) 4096        separable_conv2d_9[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_2 (Concatenate)     (None, 8, 8, 1024)   0           batch_normalization_v1_12[0][0]  \n",
            "                                                                 max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2D)  (None, 8, 8, 1024)   0           batch_normalization_v1_9[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_3 (Concatenate)     (None, 8, 8, 2048)   0           concatenate_2[0][0]              \n",
            "                                                                 max_pooling2d_2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_11 (LeakyReLU)      (None, 8, 8, 2048)   0           concatenate_3[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d (Conv2D)                 (None, 8, 8, 200)    409600      leaky_re_lu_11[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "global_average_pooling2d (Globa (None, 200)          0           conv2d[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation (Activation)         (None, 200)          0           global_average_pooling2d[0][0]   \n",
            "==================================================================================================\n",
            "Total params: 4,209,819\n",
            "Trainable params: 4,196,123\n",
            "Non-trainable params: 13,696\n",
            "__________________________________________________________________________________________________\n",
            "Found 100000 images belonging to 200 classes.\n",
            "Found 10000 images belonging to 200 classes.\n",
            "Epoch 1/50\n",
            "INFO:tensorflow:New input shapes; (re-)compiling: mode=train (# of cores 8), [TensorSpec(shape=(128,), dtype=tf.int32, name='core_id0'), TensorSpec(shape=(128, 32, 32, 3), dtype=tf.float32, name='input_1_10'), TensorSpec(shape=(128, 200), dtype=tf.float32, name='activation_target_30')]\n",
            "INFO:tensorflow:Overriding default placeholder.\n",
            "INFO:tensorflow:Remapping placeholder for input_1\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/tpu/python/tpu/keras_support.py:302: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "INFO:tensorflow:Started compiling\n",
            "INFO:tensorflow:Finished compiling. Time elapsed: 28.357731819152832 secs\n",
            "INFO:tensorflow:Setting weights on TPU model.\n",
            "96/97 [============================>.] - ETA: 2s - loss: 5.0774 - acc: 0.0270INFO:tensorflow:New input shapes; (re-)compiling: mode=eval (# of cores 8), [TensorSpec(shape=(128,), dtype=tf.int32, name='core_id_10'), TensorSpec(shape=(128, 32, 32, 3), dtype=tf.float32, name='input_1_10'), TensorSpec(shape=(128, 200), dtype=tf.float32, name='activation_target_30')]\n",
            "INFO:tensorflow:Overriding default placeholder.\n",
            "INFO:tensorflow:Remapping placeholder for input_1\n",
            "INFO:tensorflow:Started compiling\n",
            "INFO:tensorflow:Finished compiling. Time elapsed: 5.986413955688477 secs\n",
            " 9/10 [==========================>...] - ETA: 1s - loss: 5.2985 - acc: 0.0052INFO:tensorflow:New input shapes; (re-)compiling: mode=eval (# of cores 8), [TensorSpec(shape=(98,), dtype=tf.int32, name='core_id_10'), TensorSpec(shape=(98, 32, 32, 3), dtype=tf.float32, name='input_1_10'), TensorSpec(shape=(98, 200), dtype=tf.float32, name='activation_target_30')]\n",
            "INFO:tensorflow:Overriding default placeholder.\n",
            "INFO:tensorflow:Remapping placeholder for input_1\n",
            "INFO:tensorflow:Started compiling\n",
            "INFO:tensorflow:Finished compiling. Time elapsed: 6.131758689880371 secs\n",
            "10/10 [==============================] - 19s 2s/step - loss: 5.2985 - acc: 0.0050\n",
            "INFO:tensorflow:Copying TPU weights to the CPU\n",
            "97/97 [==============================] - 235s 2s/step - loss: 5.0746 - acc: 0.0272 - val_loss: 5.2985 - val_acc: 0.0050\n",
            "Epoch 2/50\n",
            "INFO:tensorflow:New input shapes; (re-)compiling: mode=train (# of cores 8), [TensorSpec(shape=(84,), dtype=tf.int32, name='core_id0'), TensorSpec(shape=(84, 32, 32, 3), dtype=tf.float32, name='input_1_10'), TensorSpec(shape=(84, 200), dtype=tf.float32, name='activation_target_30')]\n",
            "INFO:tensorflow:Overriding default placeholder.\n",
            "INFO:tensorflow:Remapping placeholder for input_1\n",
            "INFO:tensorflow:Started compiling\n",
            "INFO:tensorflow:Finished compiling. Time elapsed: 22.24203586578369 secs\n",
            "10/10 [==============================] - 12s 1s/step - loss: 5.3017 - acc: 0.0052\n",
            "97/97 [==============================] - 189s 2s/step - loss: 4.6776 - acc: 0.0624 - val_loss: 5.3017 - val_acc: 0.0052\n",
            "Epoch 3/50\n",
            "10/10 [==============================] - 12s 1s/step - loss: 5.3189 - acc: 0.0050\n",
            "97/97 [==============================] - 173s 2s/step - loss: 4.4384 - acc: 0.0911 - val_loss: 5.3189 - val_acc: 0.0050\n",
            "Epoch 4/50\n",
            "10/10 [==============================] - 12s 1s/step - loss: 5.5136 - acc: 0.0058\n",
            "97/97 [==============================] - 174s 2s/step - loss: 4.2476 - acc: 0.1159 - val_loss: 5.5136 - val_acc: 0.0058\n",
            "Epoch 5/50\n",
            "10/10 [==============================] - 12s 1s/step - loss: 5.3225 - acc: 0.0178\n",
            "97/97 [==============================] - 173s 2s/step - loss: 4.0955 - acc: 0.1359 - val_loss: 5.3225 - val_acc: 0.0178\n",
            "Epoch 6/50\n",
            "10/10 [==============================] - 13s 1s/step - loss: 4.5713 - acc: 0.0870\n",
            "INFO:tensorflow:Copying TPU weights to the CPU\n",
            "97/97 [==============================] - 179s 2s/step - loss: 3.9570 - acc: 0.1556 - val_loss: 4.5713 - val_acc: 0.0870\n",
            "Epoch 7/50\n",
            "10/10 [==============================] - 12s 1s/step - loss: 3.7155 - acc: 0.1868\n",
            "INFO:tensorflow:Copying TPU weights to the CPU\n",
            "97/97 [==============================] - 177s 2s/step - loss: 3.8352 - acc: 0.1746 - val_loss: 3.7155 - val_acc: 0.1868\n",
            "Epoch 8/50\n",
            "10/10 [==============================] - 13s 1s/step - loss: 3.6226 - acc: 0.2225\n",
            "INFO:tensorflow:Copying TPU weights to the CPU\n",
            "97/97 [==============================] - 176s 2s/step - loss: 3.7344 - acc: 0.1893 - val_loss: 3.6226 - val_acc: 0.2225\n",
            "Epoch 9/50\n",
            "10/10 [==============================] - 12s 1s/step - loss: 3.3809 - acc: 0.2486\n",
            "INFO:tensorflow:Copying TPU weights to the CPU\n",
            "97/97 [==============================] - 177s 2s/step - loss: 3.6544 - acc: 0.2055 - val_loss: 3.3809 - val_acc: 0.2486\n",
            "Epoch 10/50\n",
            "10/10 [==============================] - 12s 1s/step - loss: 3.5307 - acc: 0.2400\n",
            "97/97 [==============================] - 175s 2s/step - loss: 3.5608 - acc: 0.2171 - val_loss: 3.5307 - val_acc: 0.2400\n",
            "Epoch 11/50\n",
            "10/10 [==============================] - 12s 1s/step - loss: 3.3943 - acc: 0.2570\n",
            "97/97 [==============================] - 177s 2s/step - loss: 3.4994 - acc: 0.2282 - val_loss: 3.3943 - val_acc: 0.2570\n",
            "Epoch 12/50\n",
            "10/10 [==============================] - 13s 1s/step - loss: 3.3682 - acc: 0.2703\n",
            "INFO:tensorflow:Copying TPU weights to the CPU\n",
            "97/97 [==============================] - 179s 2s/step - loss: 3.4279 - acc: 0.2401 - val_loss: 3.3682 - val_acc: 0.2703\n",
            "Epoch 13/50\n",
            "10/10 [==============================] - 13s 1s/step - loss: 3.1267 - acc: 0.2959\n",
            "INFO:tensorflow:Copying TPU weights to the CPU\n",
            "97/97 [==============================] - 178s 2s/step - loss: 3.3691 - acc: 0.2497 - val_loss: 3.1267 - val_acc: 0.2959\n",
            "Epoch 14/50\n",
            "10/10 [==============================] - 13s 1s/step - loss: 3.1454 - acc: 0.2933\n",
            "97/97 [==============================] - 175s 2s/step - loss: 3.3162 - acc: 0.2600 - val_loss: 3.1454 - val_acc: 0.2933\n",
            "Epoch 15/50\n",
            "10/10 [==============================] - 13s 1s/step - loss: 3.0556 - acc: 0.3060\n",
            "INFO:tensorflow:Copying TPU weights to the CPU\n",
            "97/97 [==============================] - 179s 2s/step - loss: 3.2570 - acc: 0.2699 - val_loss: 3.0556 - val_acc: 0.3060\n",
            "Epoch 16/50\n",
            "10/10 [==============================] - 12s 1s/step - loss: 3.0697 - acc: 0.3141\n",
            "97/97 [==============================] - 175s 2s/step - loss: 3.2061 - acc: 0.2801 - val_loss: 3.0697 - val_acc: 0.3141\n",
            "Epoch 17/50\n",
            "10/10 [==============================] - 13s 1s/step - loss: 3.0659 - acc: 0.3139\n",
            "97/97 [==============================] - 177s 2s/step - loss: 3.1536 - acc: 0.2883 - val_loss: 3.0659 - val_acc: 0.3139\n",
            "Epoch 18/50\n",
            "10/10 [==============================] - 12s 1s/step - loss: 2.9821 - acc: 0.3317\n",
            "INFO:tensorflow:Copying TPU weights to the CPU\n",
            "97/97 [==============================] - 179s 2s/step - loss: 3.1172 - acc: 0.2953 - val_loss: 2.9821 - val_acc: 0.3317\n",
            "Epoch 19/50\n",
            "10/10 [==============================] - 12s 1s/step - loss: 2.9321 - acc: 0.3352\n",
            "INFO:tensorflow:Copying TPU weights to the CPU\n",
            "97/97 [==============================] - 176s 2s/step - loss: 3.0689 - acc: 0.3034 - val_loss: 2.9321 - val_acc: 0.3352\n",
            "Epoch 20/50\n",
            "10/10 [==============================] - 13s 1s/step - loss: 2.8673 - acc: 0.3473\n",
            "INFO:tensorflow:Copying TPU weights to the CPU\n",
            "97/97 [==============================] - 177s 2s/step - loss: 3.0304 - acc: 0.3114 - val_loss: 2.8673 - val_acc: 0.3473\n",
            "Epoch 21/50\n",
            "10/10 [==============================] - 13s 1s/step - loss: 2.9510 - acc: 0.3369\n",
            "97/97 [==============================] - 174s 2s/step - loss: 2.9952 - acc: 0.3158 - val_loss: 2.9510 - val_acc: 0.3369\n",
            "Epoch 22/50\n",
            "10/10 [==============================] - 12s 1s/step - loss: 2.8906 - acc: 0.3489\n",
            "97/97 [==============================] - 176s 2s/step - loss: 2.9525 - acc: 0.3244 - val_loss: 2.8906 - val_acc: 0.3489\n",
            "Epoch 23/50\n",
            "10/10 [==============================] - 13s 1s/step - loss: 2.9012 - acc: 0.3454\n",
            "97/97 [==============================] - 178s 2s/step - loss: 2.9194 - acc: 0.3298 - val_loss: 2.9012 - val_acc: 0.3454\n",
            "Epoch 24/50\n",
            "10/10 [==============================] - 12s 1s/step - loss: 2.8729 - acc: 0.3489\n",
            "97/97 [==============================] - 176s 2s/step - loss: 2.8948 - acc: 0.3335 - val_loss: 2.8729 - val_acc: 0.3489\n",
            "Epoch 25/50\n",
            "10/10 [==============================] - 12s 1s/step - loss: 2.8178 - acc: 0.3546\n",
            "INFO:tensorflow:Copying TPU weights to the CPU\n",
            "97/97 [==============================] - 180s 2s/step - loss: 2.8521 - acc: 0.3420 - val_loss: 2.8178 - val_acc: 0.3546\n",
            "Epoch 26/50\n",
            "10/10 [==============================] - 12s 1s/step - loss: 2.8372 - acc: 0.3663\n",
            "97/97 [==============================] - 173s 2s/step - loss: 2.8235 - acc: 0.3482 - val_loss: 2.8372 - val_acc: 0.3663\n",
            "Epoch 27/50\n",
            "10/10 [==============================] - 12s 1s/step - loss: 2.8350 - acc: 0.3719\n",
            "97/97 [==============================] - 175s 2s/step - loss: 2.8026 - acc: 0.3518 - val_loss: 2.8350 - val_acc: 0.3719\n",
            "Epoch 28/50\n",
            "10/10 [==============================] - 13s 1s/step - loss: 2.9483 - acc: 0.3499\n",
            "97/97 [==============================] - 177s 2s/step - loss: 2.7624 - acc: 0.3591 - val_loss: 2.9483 - val_acc: 0.3499\n",
            "Epoch 29/50\n",
            "10/10 [==============================] - 12s 1s/step - loss: 2.7744 - acc: 0.3855\n",
            "INFO:tensorflow:Copying TPU weights to the CPU\n",
            "97/97 [==============================] - 178s 2s/step - loss: 2.7424 - acc: 0.3628 - val_loss: 2.7744 - val_acc: 0.3855\n",
            "Epoch 30/50\n",
            "10/10 [==============================] - 12s 1s/step - loss: 2.7383 - acc: 0.3852\n",
            "INFO:tensorflow:Copying TPU weights to the CPU\n",
            "97/97 [==============================] - 177s 2s/step - loss: 2.7165 - acc: 0.3694 - val_loss: 2.7383 - val_acc: 0.3852\n",
            "Epoch 31/50\n",
            "10/10 [==============================] - 14s 1s/step - loss: 2.6578 - acc: 0.3908\n",
            "INFO:tensorflow:Copying TPU weights to the CPU\n",
            "97/97 [==============================] - 178s 2s/step - loss: 2.6906 - acc: 0.3732 - val_loss: 2.6578 - val_acc: 0.3908\n",
            "Epoch 32/50\n",
            "10/10 [==============================] - 13s 1s/step - loss: 2.7493 - acc: 0.3859\n",
            "97/97 [==============================] - 175s 2s/step - loss: 2.6649 - acc: 0.3774 - val_loss: 2.7493 - val_acc: 0.3859\n",
            "Epoch 33/50\n",
            "10/10 [==============================] - 12s 1s/step - loss: 2.6331 - acc: 0.4006\n",
            "INFO:tensorflow:Copying TPU weights to the CPU\n",
            "97/97 [==============================] - 180s 2s/step - loss: 2.6452 - acc: 0.3828 - val_loss: 2.6331 - val_acc: 0.4006\n",
            "Epoch 34/50\n",
            "10/10 [==============================] - 13s 1s/step - loss: 2.6484 - acc: 0.4013\n",
            "97/97 [==============================] - 175s 2s/step - loss: 2.6226 - acc: 0.3849 - val_loss: 2.6484 - val_acc: 0.4013\n",
            "Epoch 35/50\n",
            "10/10 [==============================] - 13s 1s/step - loss: 2.7304 - acc: 0.3970\n",
            "97/97 [==============================] - 177s 2s/step - loss: 2.5761 - acc: 0.3949 - val_loss: 2.7304 - val_acc: 0.3970\n",
            "Epoch 36/50\n",
            "10/10 [==============================] - 13s 1s/step - loss: 2.5951 - acc: 0.4109\n",
            "INFO:tensorflow:Copying TPU weights to the CPU\n",
            "97/97 [==============================] - 179s 2s/step - loss: 2.5673 - acc: 0.3961 - val_loss: 2.5951 - val_acc: 0.4109\n",
            "Epoch 37/50\n",
            "10/10 [==============================] - 13s 1s/step - loss: 2.6416 - acc: 0.4073\n",
            "97/97 [==============================] - 175s 2s/step - loss: 2.5489 - acc: 0.4002 - val_loss: 2.6416 - val_acc: 0.4073\n",
            "Epoch 38/50\n",
            "10/10 [==============================] - 13s 1s/step - loss: 2.6045 - acc: 0.4073\n",
            "97/97 [==============================] - 178s 2s/step - loss: 2.5222 - acc: 0.4039 - val_loss: 2.6045 - val_acc: 0.4073\n",
            "Epoch 39/50\n",
            "10/10 [==============================] - 13s 1s/step - loss: 2.6136 - acc: 0.4109\n",
            "97/97 [==============================] - 176s 2s/step - loss: 2.4974 - acc: 0.4096 - val_loss: 2.6136 - val_acc: 0.4109\n",
            "Epoch 40/50\n",
            "10/10 [==============================] - 13s 1s/step - loss: 2.6118 - acc: 0.4057\n",
            "97/97 [==============================] - 177s 2s/step - loss: 2.4753 - acc: 0.4120 - val_loss: 2.6118 - val_acc: 0.4057\n",
            "Epoch 41/50\n",
            "10/10 [==============================] - 12s 1s/step - loss: 2.6470 - acc: 0.4089\n",
            "97/97 [==============================] - 177s 2s/step - loss: 2.4526 - acc: 0.4175 - val_loss: 2.6470 - val_acc: 0.4089\n",
            "Epoch 42/50\n",
            "10/10 [==============================] - 13s 1s/step - loss: 2.6432 - acc: 0.4090\n",
            "97/97 [==============================] - 176s 2s/step - loss: 2.4360 - acc: 0.4208 - val_loss: 2.6432 - val_acc: 0.4090\n",
            "Epoch 43/50\n",
            "10/10 [==============================] - 13s 1s/step - loss: 2.6526 - acc: 0.4144\n",
            "97/97 [==============================] - 176s 2s/step - loss: 2.4158 - acc: 0.4264 - val_loss: 2.6526 - val_acc: 0.4144\n",
            "Epoch 44/50\n",
            "10/10 [==============================] - 13s 1s/step - loss: 2.6840 - acc: 0.4106\n",
            "97/97 [==============================] - 176s 2s/step - loss: 2.3995 - acc: 0.4287 - val_loss: 2.6840 - val_acc: 0.4106\n",
            "Epoch 45/50\n",
            "10/10 [==============================] - 12s 1s/step - loss: 2.7111 - acc: 0.4041\n",
            "97/97 [==============================] - 175s 2s/step - loss: 2.3696 - acc: 0.4334 - val_loss: 2.7111 - val_acc: 0.4041\n",
            "Epoch 46/50\n",
            "10/10 [==============================] - 13s 1s/step - loss: 2.6833 - acc: 0.4072\n",
            "97/97 [==============================] - 177s 2s/step - loss: 2.3685 - acc: 0.4339 - val_loss: 2.6833 - val_acc: 0.4072\n",
            "Epoch 47/50\n",
            "10/10 [==============================] - 12s 1s/step - loss: 2.5366 - acc: 0.4293\n",
            "INFO:tensorflow:Copying TPU weights to the CPU\n",
            "97/97 [==============================] - 178s 2s/step - loss: 2.3385 - acc: 0.4391 - val_loss: 2.5366 - val_acc: 0.4293\n",
            "Epoch 48/50\n",
            "10/10 [==============================] - 12s 1s/step - loss: 2.5772 - acc: 0.4264\n",
            "97/97 [==============================] - 175s 2s/step - loss: 2.3239 - acc: 0.4437 - val_loss: 2.5772 - val_acc: 0.4264\n",
            "Epoch 49/50\n",
            "10/10 [==============================] - 12s 1s/step - loss: 2.6221 - acc: 0.4212\n",
            "97/97 [==============================] - 177s 2s/step - loss: 2.3161 - acc: 0.4431 - val_loss: 2.6221 - val_acc: 0.4212\n",
            "Epoch 50/50\n",
            "10/10 [==============================] - 13s 1s/step - loss: 2.7662 - acc: 0.4120\n",
            "97/97 [==============================] - 177s 2s/step - loss: 2.2895 - acc: 0.4482 - val_loss: 2.7662 - val_acc: 0.4120\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pgT95OZfOo36",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 5388
        },
        "outputId": "ff729bfa-2039-45d1-dc03-9cbc32fc1f8c"
      },
      "source": [
        "learning_strategy(image_size=32,previous_epoch=50,epoch_size=100,batchsize=1024,learning_rate=0.0006)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading previous model with least val loss: /gdrive/My Drive/tpuweights/vddddAssignment4Amodel_47_2.54.hdf5\n",
            "INFO:tensorflow:Querying Tensorflow master (grpc://10.83.166.114:8470) for TPU system metadata.\n",
            "INFO:tensorflow:Found TPU system:\n",
            "INFO:tensorflow:*** Num TPU Cores: 8\n",
            "INFO:tensorflow:*** Num TPU Workers: 1\n",
            "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, -1, 13500332730615543303)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 17179869184, 10911548605046438221)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 17179869184, 13310310715681238334)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 17179869184, 13603759284196199019)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 17179869184, 13271506822373635801)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 17179869184, 12865063715420442997)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 17179869184, 695705940928788856)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 17179869184, 11427421158650622169)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 17179869184, 17740846334454896448)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 17179869184, 13627862481255270662)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 17179869184, 12438717959147637322)\n",
            "WARNING:tensorflow:tpu_model (from tensorflow.contrib.tpu.python.tpu.keras_support) is experimental and may change or be removed at any time, and without warning.\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            (None, 32, 32, 3)    0                                            \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d (SeparableConv (None, 32, 32, 64)   219         input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1 (BatchNo (None, 32, 32, 64)   256         separable_conv2d[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu (LeakyReLU)         (None, 32, 32, 64)   0           batch_normalization_v1[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_1 (SeparableCo (None, 32, 32, 128)  8768        leaky_re_lu[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_1 (Batch (None, 32, 32, 128)  512         separable_conv2d_1[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_1 (LeakyReLU)       (None, 32, 32, 128)  0           batch_normalization_v1_1[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_2 (SeparableCo (None, 32, 32, 256)  33920       leaky_re_lu_1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_2 (Batch (None, 32, 32, 256)  1024        separable_conv2d_2[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_2 (LeakyReLU)       (None, 32, 32, 256)  0           batch_normalization_v1_2[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_3 (SeparableCo (None, 32, 32, 512)  133376      leaky_re_lu_2[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_3 (Batch (None, 32, 32, 512)  2048        separable_conv2d_3[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_3 (LeakyReLU)       (None, 32, 32, 512)  0           batch_normalization_v1_3[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_4 (SeparableCo (None, 32, 32, 1024) 528896      leaky_re_lu_3[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_4 (Batch (None, 32, 32, 1024) 4096        separable_conv2d_4[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_4 (LeakyReLU)       (None, 32, 32, 1024) 0           batch_normalization_v1_4[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_5 (SeparableCo (None, 32, 32, 256)  271360      leaky_re_lu_4[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_5 (Batch (None, 32, 32, 256)  1024        separable_conv2d_5[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "concatenate (Concatenate)       (None, 32, 32, 512)  0           batch_normalization_v1_5[0][0]   \n",
            "                                                                 leaky_re_lu_2[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_5 (LeakyReLU)       (None, 32, 32, 512)  0           concatenate[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D)    (None, 16, 16, 512)  0           leaky_re_lu_5[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_6 (SeparableCo (None, 16, 16, 512)  266752      max_pooling2d[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_6 (Batch (None, 16, 16, 512)  2048        separable_conv2d_6[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_6 (LeakyReLU)       (None, 16, 16, 512)  0           batch_normalization_v1_6[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_7 (SeparableCo (None, 16, 16, 1024) 528896      leaky_re_lu_6[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_7 (Batch (None, 16, 16, 1024) 4096        separable_conv2d_7[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_7 (LeakyReLU)       (None, 16, 16, 1024) 0           batch_normalization_v1_7[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_8 (SeparableCo (None, 16, 16, 256)  271360      leaky_re_lu_7[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_8 (Batch (None, 16, 16, 256)  1024        separable_conv2d_8[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_1 (Concatenate)     (None, 16, 16, 768)  0           batch_normalization_v1_8[0][0]   \n",
            "                                                                 max_pooling2d[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_8 (LeakyReLU)       (None, 16, 16, 768)  0           concatenate_1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2D)  (None, 8, 8, 768)    0           leaky_re_lu_8[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_10 (SeparableC (None, 8, 8, 512)    400128      max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_10 (Batc (None, 8, 8, 512)    2048        separable_conv2d_10[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_9 (LeakyReLU)       (None, 8, 8, 512)    0           batch_normalization_v1_10[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_11 (SeparableC (None, 8, 8, 1024)   528896      leaky_re_lu_9[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_11 (Batc (None, 8, 8, 1024)   4096        separable_conv2d_11[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_10 (LeakyReLU)      (None, 8, 8, 1024)   0           batch_normalization_v1_11[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_12 (SeparableC (None, 8, 8, 256)    271360      leaky_re_lu_10[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_9 (SeparableCo (None, 16, 16, 1024) 528896      max_pooling2d[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_12 (Batc (None, 8, 8, 256)    1024        separable_conv2d_12[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_9 (Batch (None, 16, 16, 1024) 4096        separable_conv2d_9[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_2 (Concatenate)     (None, 8, 8, 1024)   0           batch_normalization_v1_12[0][0]  \n",
            "                                                                 max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2D)  (None, 8, 8, 1024)   0           batch_normalization_v1_9[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_3 (Concatenate)     (None, 8, 8, 2048)   0           concatenate_2[0][0]              \n",
            "                                                                 max_pooling2d_2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_11 (LeakyReLU)      (None, 8, 8, 2048)   0           concatenate_3[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d (Conv2D)                 (None, 8, 8, 200)    409600      leaky_re_lu_11[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "global_average_pooling2d (Globa (None, 200)          0           conv2d[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation (Activation)         (None, 200)          0           global_average_pooling2d[0][0]   \n",
            "==================================================================================================\n",
            "Total params: 4,209,819\n",
            "Trainable params: 4,196,123\n",
            "Non-trainable params: 13,696\n",
            "__________________________________________________________________________________________________\n",
            "Found 100000 images belonging to 200 classes.\n",
            "Found 10000 images belonging to 200 classes.\n",
            "Epoch 51/100\n",
            "INFO:tensorflow:New input shapes; (re-)compiling: mode=train (# of cores 8), [TensorSpec(shape=(128,), dtype=tf.int32, name='core_id0'), TensorSpec(shape=(128, 32, 32, 3), dtype=tf.float32, name='input_1_10'), TensorSpec(shape=(128, 200), dtype=tf.float32, name='activation_target_30')]\n",
            "INFO:tensorflow:Overriding default placeholder.\n",
            "INFO:tensorflow:Remapping placeholder for input_1\n",
            "INFO:tensorflow:Started compiling\n",
            "INFO:tensorflow:Finished compiling. Time elapsed: 27.960872411727905 secs\n",
            "INFO:tensorflow:Setting weights on TPU model.\n",
            "96/97 [============================>.] - ETA: 2s - loss: 2.2468 - acc: 0.4594INFO:tensorflow:New input shapes; (re-)compiling: mode=eval (# of cores 8), [TensorSpec(shape=(128,), dtype=tf.int32, name='core_id_10'), TensorSpec(shape=(128, 32, 32, 3), dtype=tf.float32, name='input_1_10'), TensorSpec(shape=(128, 200), dtype=tf.float32, name='activation_target_30')]\n",
            "INFO:tensorflow:Overriding default placeholder.\n",
            "INFO:tensorflow:Remapping placeholder for input_1\n",
            "INFO:tensorflow:Started compiling\n",
            "INFO:tensorflow:Finished compiling. Time elapsed: 6.44977068901062 secs\n",
            " 9/10 [==========================>...] - ETA: 1s - loss: 2.3888 - acc: 0.4515INFO:tensorflow:New input shapes; (re-)compiling: mode=eval (# of cores 8), [TensorSpec(shape=(98,), dtype=tf.int32, name='core_id_10'), TensorSpec(shape=(98, 32, 32, 3), dtype=tf.float32, name='input_1_10'), TensorSpec(shape=(98, 200), dtype=tf.float32, name='activation_target_30')]\n",
            "INFO:tensorflow:Overriding default placeholder.\n",
            "INFO:tensorflow:Remapping placeholder for input_1\n",
            "INFO:tensorflow:Started compiling\n",
            "INFO:tensorflow:Finished compiling. Time elapsed: 6.240299224853516 secs\n",
            "10/10 [==============================] - 19s 2s/step - loss: 2.3843 - acc: 0.4523\n",
            "INFO:tensorflow:Copying TPU weights to the CPU\n",
            "97/97 [==============================] - 249s 3s/step - loss: 2.2465 - acc: 0.4594 - val_loss: 2.3843 - val_acc: 0.4523\n",
            "Epoch 52/100\n",
            "INFO:tensorflow:New input shapes; (re-)compiling: mode=train (# of cores 8), [TensorSpec(shape=(84,), dtype=tf.int32, name='core_id0'), TensorSpec(shape=(84, 32, 32, 3), dtype=tf.float32, name='input_1_10'), TensorSpec(shape=(84, 200), dtype=tf.float32, name='activation_target_30')]\n",
            "INFO:tensorflow:Overriding default placeholder.\n",
            "INFO:tensorflow:Remapping placeholder for input_1\n",
            "INFO:tensorflow:Started compiling\n",
            "INFO:tensorflow:Finished compiling. Time elapsed: 21.489742517471313 secs\n",
            "10/10 [==============================] - 12s 1s/step - loss: 2.4459 - acc: 0.4465\n",
            "97/97 [==============================] - 185s 2s/step - loss: 2.1974 - acc: 0.4701 - val_loss: 2.4459 - val_acc: 0.4465\n",
            "Epoch 53/100\n",
            "10/10 [==============================] - 12s 1s/step - loss: 2.3937 - acc: 0.4553\n",
            "97/97 [==============================] - 172s 2s/step - loss: 2.1768 - acc: 0.4739 - val_loss: 2.3937 - val_acc: 0.4553\n",
            "Epoch 54/100\n",
            "10/10 [==============================] - 12s 1s/step - loss: 2.4394 - acc: 0.4505\n",
            "97/97 [==============================] - 171s 2s/step - loss: 2.1645 - acc: 0.4751 - val_loss: 2.4394 - val_acc: 0.4505\n",
            "Epoch 55/100\n",
            "10/10 [==============================] - 12s 1s/step - loss: 2.5521 - acc: 0.4393\n",
            "97/97 [==============================] - 172s 2s/step - loss: 2.1464 - acc: 0.4791 - val_loss: 2.5521 - val_acc: 0.4393\n",
            "Epoch 56/100\n",
            "10/10 [==============================] - 12s 1s/step - loss: 2.4046 - acc: 0.4518\n",
            "97/97 [==============================] - 171s 2s/step - loss: 2.1274 - acc: 0.4861 - val_loss: 2.4046 - val_acc: 0.4518\n",
            "Epoch 57/100\n",
            "10/10 [==============================] - 12s 1s/step - loss: 2.5189 - acc: 0.4450\n",
            "97/97 [==============================] - 172s 2s/step - loss: 2.1178 - acc: 0.4876 - val_loss: 2.5189 - val_acc: 0.4450\n",
            "Epoch 58/100\n",
            "10/10 [==============================] - 12s 1s/step - loss: 2.5128 - acc: 0.4477\n",
            "97/97 [==============================] - 170s 2s/step - loss: 2.0989 - acc: 0.4887 - val_loss: 2.5128 - val_acc: 0.4477\n",
            "Epoch 59/100\n",
            "10/10 [==============================] - 12s 1s/step - loss: 2.5235 - acc: 0.4437\n",
            "97/97 [==============================] - 171s 2s/step - loss: 2.0930 - acc: 0.4899 - val_loss: 2.5235 - val_acc: 0.4437\n",
            "Epoch 60/100\n",
            "10/10 [==============================] - 12s 1s/step - loss: 2.5956 - acc: 0.4344\n",
            "97/97 [==============================] - 171s 2s/step - loss: 2.0689 - acc: 0.4947 - val_loss: 2.5956 - val_acc: 0.4344\n",
            "Epoch 61/100\n",
            "10/10 [==============================] - 12s 1s/step - loss: 2.5202 - acc: 0.4454\n",
            "97/97 [==============================] - 171s 2s/step - loss: 2.0673 - acc: 0.4980 - val_loss: 2.5202 - val_acc: 0.4454\n",
            "Epoch 62/100\n",
            "10/10 [==============================] - 12s 1s/step - loss: 2.4758 - acc: 0.4516\n",
            "97/97 [==============================] - 172s 2s/step - loss: 2.0490 - acc: 0.4972 - val_loss: 2.4758 - val_acc: 0.4516\n",
            "Epoch 63/100\n",
            "10/10 [==============================] - 12s 1s/step - loss: 2.5089 - acc: 0.4424\n",
            "97/97 [==============================] - 170s 2s/step - loss: 2.0382 - acc: 0.5016 - val_loss: 2.5089 - val_acc: 0.4424\n",
            "Epoch 64/100\n",
            "10/10 [==============================] - 12s 1s/step - loss: 2.4508 - acc: 0.4532\n",
            "97/97 [==============================] - 172s 2s/step - loss: 2.0267 - acc: 0.5023 - val_loss: 2.4508 - val_acc: 0.4532\n",
            "Epoch 65/100\n",
            "10/10 [==============================] - 12s 1s/step - loss: 2.5706 - acc: 0.4427\n",
            "97/97 [==============================] - 170s 2s/step - loss: 2.0042 - acc: 0.5077 - val_loss: 2.5706 - val_acc: 0.4427\n",
            "Epoch 66/100\n",
            "10/10 [==============================] - 12s 1s/step - loss: 2.6266 - acc: 0.4293\n",
            "97/97 [==============================] - 171s 2s/step - loss: 2.0075 - acc: 0.5064 - val_loss: 2.6266 - val_acc: 0.4293\n",
            "Epoch 67/100\n",
            "10/10 [==============================] - 12s 1s/step - loss: 2.5191 - acc: 0.4573\n",
            "97/97 [==============================] - 171s 2s/step - loss: 1.9875 - acc: 0.5097 - val_loss: 2.5191 - val_acc: 0.4573\n",
            "Epoch 68/100\n",
            "10/10 [==============================] - 12s 1s/step - loss: 2.5361 - acc: 0.4518\n",
            "97/97 [==============================] - 171s 2s/step - loss: 1.9733 - acc: 0.5130 - val_loss: 2.5361 - val_acc: 0.4518\n",
            "Epoch 69/100\n",
            "10/10 [==============================] - 12s 1s/step - loss: 2.5193 - acc: 0.4517\n",
            "97/97 [==============================] - 170s 2s/step - loss: 1.9625 - acc: 0.5168 - val_loss: 2.5193 - val_acc: 0.4517\n",
            "Epoch 70/100\n",
            "10/10 [==============================] - 12s 1s/step - loss: 2.5659 - acc: 0.4469\n",
            "97/97 [==============================] - 172s 2s/step - loss: 1.9519 - acc: 0.5182 - val_loss: 2.5659 - val_acc: 0.4469\n",
            "Epoch 71/100\n",
            "10/10 [==============================] - 12s 1s/step - loss: 2.5211 - acc: 0.4574\n",
            "97/97 [==============================] - 171s 2s/step - loss: 1.9487 - acc: 0.5189 - val_loss: 2.5211 - val_acc: 0.4574\n",
            "Epoch 72/100\n",
            "10/10 [==============================] - 12s 1s/step - loss: 2.5989 - acc: 0.4481\n",
            "97/97 [==============================] - 170s 2s/step - loss: 1.9318 - acc: 0.5240 - val_loss: 2.5989 - val_acc: 0.4481\n",
            "Epoch 73/100\n",
            "10/10 [==============================] - 12s 1s/step - loss: 2.5489 - acc: 0.4499\n",
            "97/97 [==============================] - 171s 2s/step - loss: 1.9200 - acc: 0.5240 - val_loss: 2.5489 - val_acc: 0.4499\n",
            "Epoch 74/100\n",
            "10/10 [==============================] - 13s 1s/step - loss: 2.5614 - acc: 0.4492\n",
            "97/97 [==============================] - 170s 2s/step - loss: 1.9133 - acc: 0.5273 - val_loss: 2.5614 - val_acc: 0.4492\n",
            "Epoch 75/100\n",
            "10/10 [==============================] - 12s 1s/step - loss: 2.6256 - acc: 0.4432\n",
            "97/97 [==============================] - 171s 2s/step - loss: 1.8958 - acc: 0.5297 - val_loss: 2.6256 - val_acc: 0.4432\n",
            "Epoch 76/100\n",
            "10/10 [==============================] - 12s 1s/step - loss: 2.5983 - acc: 0.4458\n",
            "97/97 [==============================] - 170s 2s/step - loss: 1.8793 - acc: 0.5315 - val_loss: 2.5983 - val_acc: 0.4458\n",
            "Epoch 77/100\n",
            "10/10 [==============================] - 12s 1s/step - loss: 2.6352 - acc: 0.4469\n",
            "97/97 [==============================] - 171s 2s/step - loss: 1.8738 - acc: 0.5329 - val_loss: 2.6352 - val_acc: 0.4469\n",
            "Epoch 78/100\n",
            "10/10 [==============================] - 12s 1s/step - loss: 2.5856 - acc: 0.4474\n",
            "97/97 [==============================] - 171s 2s/step - loss: 1.8534 - acc: 0.5380 - val_loss: 2.5856 - val_acc: 0.4474\n",
            "Epoch 79/100\n",
            "10/10 [==============================] - 12s 1s/step - loss: 2.6588 - acc: 0.4421\n",
            "97/97 [==============================] - 171s 2s/step - loss: 1.8479 - acc: 0.5388 - val_loss: 2.6588 - val_acc: 0.4421\n",
            "Epoch 80/100\n",
            "10/10 [==============================] - 12s 1s/step - loss: 2.5881 - acc: 0.4516\n",
            "97/97 [==============================] - 170s 2s/step - loss: 1.8455 - acc: 0.5401 - val_loss: 2.5881 - val_acc: 0.4516\n",
            "Epoch 81/100\n",
            "10/10 [==============================] - 12s 1s/step - loss: 2.5475 - acc: 0.4526\n",
            "97/97 [==============================] - 171s 2s/step - loss: 1.8317 - acc: 0.5412 - val_loss: 2.5475 - val_acc: 0.4526\n",
            "Epoch 82/100\n",
            "10/10 [==============================] - 13s 1s/step - loss: 2.5722 - acc: 0.4572\n",
            "97/97 [==============================] - 172s 2s/step - loss: 1.8225 - acc: 0.5451 - val_loss: 2.5722 - val_acc: 0.4572\n",
            "Epoch 83/100\n",
            "10/10 [==============================] - 12s 1s/step - loss: 2.6026 - acc: 0.4535\n",
            "97/97 [==============================] - 171s 2s/step - loss: 1.8172 - acc: 0.5456 - val_loss: 2.6026 - val_acc: 0.4535\n",
            "Epoch 84/100\n",
            "10/10 [==============================] - 12s 1s/step - loss: 2.7044 - acc: 0.4431\n",
            "97/97 [==============================] - 172s 2s/step - loss: 1.8079 - acc: 0.5469 - val_loss: 2.7044 - val_acc: 0.4431\n",
            "Epoch 85/100\n",
            "10/10 [==============================] - 12s 1s/step - loss: 2.6524 - acc: 0.4466\n",
            "97/97 [==============================] - 171s 2s/step - loss: 1.7823 - acc: 0.5537 - val_loss: 2.6524 - val_acc: 0.4466\n",
            "Epoch 86/100\n",
            "10/10 [==============================] - 12s 1s/step - loss: 2.7258 - acc: 0.4394\n",
            "97/97 [==============================] - 172s 2s/step - loss: 1.7773 - acc: 0.5540 - val_loss: 2.7258 - val_acc: 0.4394\n",
            "Epoch 87/100\n",
            "10/10 [==============================] - 12s 1s/step - loss: 2.6529 - acc: 0.4491\n",
            "97/97 [==============================] - 172s 2s/step - loss: 1.7695 - acc: 0.5559 - val_loss: 2.6529 - val_acc: 0.4491\n",
            "Epoch 88/100\n",
            "10/10 [==============================] - 12s 1s/step - loss: 2.6897 - acc: 0.4479\n",
            "97/97 [==============================] - 172s 2s/step - loss: 1.7688 - acc: 0.5577 - val_loss: 2.6897 - val_acc: 0.4479\n",
            "Epoch 89/100\n",
            "10/10 [==============================] - 13s 1s/step - loss: 2.7091 - acc: 0.4446\n",
            "97/97 [==============================] - 178s 2s/step - loss: 1.7601 - acc: 0.5582 - val_loss: 2.7091 - val_acc: 0.4446\n",
            "Epoch 90/100\n",
            "10/10 [==============================] - 13s 1s/step - loss: 2.7754 - acc: 0.4383\n",
            "97/97 [==============================] - 181s 2s/step - loss: 1.7353 - acc: 0.5643 - val_loss: 2.7754 - val_acc: 0.4383\n",
            "Epoch 91/100\n",
            "10/10 [==============================] - 13s 1s/step - loss: 2.6903 - acc: 0.4455\n",
            "97/97 [==============================] - 181s 2s/step - loss: 1.7304 - acc: 0.5637 - val_loss: 2.6903 - val_acc: 0.4455\n",
            "Epoch 92/100\n",
            "10/10 [==============================] - 13s 1s/step - loss: 2.7174 - acc: 0.4436\n",
            "97/97 [==============================] - 180s 2s/step - loss: 1.7257 - acc: 0.5660 - val_loss: 2.7174 - val_acc: 0.4436\n",
            "Epoch 93/100\n",
            "10/10 [==============================] - 13s 1s/step - loss: 2.6341 - acc: 0.4515\n",
            "97/97 [==============================] - 182s 2s/step - loss: 1.7102 - acc: 0.5681 - val_loss: 2.6341 - val_acc: 0.4515\n",
            "Epoch 94/100\n",
            "10/10 [==============================] - 14s 1s/step - loss: 2.7359 - acc: 0.4423\n",
            "97/97 [==============================] - 182s 2s/step - loss: 1.6950 - acc: 0.5736 - val_loss: 2.7359 - val_acc: 0.4423\n",
            "Epoch 95/100\n",
            "10/10 [==============================] - 13s 1s/step - loss: 2.7521 - acc: 0.4442\n",
            "97/97 [==============================] - 183s 2s/step - loss: 1.6927 - acc: 0.5729 - val_loss: 2.7521 - val_acc: 0.4442\n",
            "Epoch 96/100\n",
            "10/10 [==============================] - 14s 1s/step - loss: 2.6932 - acc: 0.4516\n",
            "97/97 [==============================] - 182s 2s/step - loss: 1.6861 - acc: 0.5746 - val_loss: 2.6932 - val_acc: 0.4516\n",
            "Epoch 97/100\n",
            "10/10 [==============================] - 13s 1s/step - loss: 2.7200 - acc: 0.4449\n",
            "97/97 [==============================] - 183s 2s/step - loss: 1.6772 - acc: 0.5753 - val_loss: 2.7200 - val_acc: 0.4449\n",
            "Epoch 98/100\n",
            "10/10 [==============================] - 14s 1s/step - loss: 2.8076 - acc: 0.4439\n",
            "97/97 [==============================] - 184s 2s/step - loss: 1.6996 - acc: 0.5703 - val_loss: 2.8076 - val_acc: 0.4439\n",
            "Epoch 99/100\n",
            "10/10 [==============================] - 13s 1s/step - loss: 2.7248 - acc: 0.4527\n",
            "97/97 [==============================] - 180s 2s/step - loss: 1.6931 - acc: 0.5710 - val_loss: 2.7248 - val_acc: 0.4527\n",
            "Epoch 100/100\n",
            "10/10 [==============================] - 13s 1s/step - loss: 2.8453 - acc: 0.4384\n",
            "97/97 [==============================] - 181s 2s/step - loss: 1.6839 - acc: 0.5723 - val_loss: 2.8453 - val_acc: 0.4384\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mS1G20boOs60",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 4961
        },
        "outputId": "b725f6db-d4f5-48e3-8c52-c8b26292581c"
      },
      "source": [
        "learning_strategy(image_size=48,previous_epoch=100,epoch_size=150,batchsize=1024,learning_rate=0.0006)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading previous model with least val loss: /gdrive/My Drive/tpuweights/vddddAssignment4Amodel_51_2.38.hdf5\n",
            "INFO:tensorflow:Querying Tensorflow master (grpc://10.83.166.114:8470) for TPU system metadata.\n",
            "INFO:tensorflow:Found TPU system:\n",
            "INFO:tensorflow:*** Num TPU Cores: 8\n",
            "INFO:tensorflow:*** Num TPU Workers: 1\n",
            "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, -1, 13500332730615543303)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 17179869184, 10911548605046438221)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 17179869184, 13310310715681238334)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 17179869184, 13603759284196199019)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 17179869184, 13271506822373635801)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 17179869184, 12865063715420442997)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 17179869184, 695705940928788856)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 17179869184, 11427421158650622169)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 17179869184, 17740846334454896448)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 17179869184, 13627862481255270662)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 17179869184, 12438717959147637322)\n",
            "WARNING:tensorflow:tpu_model (from tensorflow.contrib.tpu.python.tpu.keras_support) is experimental and may change or be removed at any time, and without warning.\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            (None, 48, 48, 3)    0                                            \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d (SeparableConv (None, 48, 48, 64)   219         input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1 (BatchNo (None, 48, 48, 64)   256         separable_conv2d[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu (LeakyReLU)         (None, 48, 48, 64)   0           batch_normalization_v1[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_1 (SeparableCo (None, 48, 48, 128)  8768        leaky_re_lu[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_1 (Batch (None, 48, 48, 128)  512         separable_conv2d_1[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_1 (LeakyReLU)       (None, 48, 48, 128)  0           batch_normalization_v1_1[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_2 (SeparableCo (None, 48, 48, 256)  33920       leaky_re_lu_1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_2 (Batch (None, 48, 48, 256)  1024        separable_conv2d_2[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_2 (LeakyReLU)       (None, 48, 48, 256)  0           batch_normalization_v1_2[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_3 (SeparableCo (None, 48, 48, 512)  133376      leaky_re_lu_2[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_3 (Batch (None, 48, 48, 512)  2048        separable_conv2d_3[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_3 (LeakyReLU)       (None, 48, 48, 512)  0           batch_normalization_v1_3[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_4 (SeparableCo (None, 48, 48, 1024) 528896      leaky_re_lu_3[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_4 (Batch (None, 48, 48, 1024) 4096        separable_conv2d_4[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_4 (LeakyReLU)       (None, 48, 48, 1024) 0           batch_normalization_v1_4[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_5 (SeparableCo (None, 48, 48, 256)  271360      leaky_re_lu_4[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_5 (Batch (None, 48, 48, 256)  1024        separable_conv2d_5[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "concatenate (Concatenate)       (None, 48, 48, 512)  0           batch_normalization_v1_5[0][0]   \n",
            "                                                                 leaky_re_lu_2[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_5 (LeakyReLU)       (None, 48, 48, 512)  0           concatenate[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D)    (None, 24, 24, 512)  0           leaky_re_lu_5[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_6 (SeparableCo (None, 24, 24, 512)  266752      max_pooling2d[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_6 (Batch (None, 24, 24, 512)  2048        separable_conv2d_6[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_6 (LeakyReLU)       (None, 24, 24, 512)  0           batch_normalization_v1_6[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_7 (SeparableCo (None, 24, 24, 1024) 528896      leaky_re_lu_6[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_7 (Batch (None, 24, 24, 1024) 4096        separable_conv2d_7[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_7 (LeakyReLU)       (None, 24, 24, 1024) 0           batch_normalization_v1_7[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_8 (SeparableCo (None, 24, 24, 256)  271360      leaky_re_lu_7[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_8 (Batch (None, 24, 24, 256)  1024        separable_conv2d_8[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_1 (Concatenate)     (None, 24, 24, 768)  0           batch_normalization_v1_8[0][0]   \n",
            "                                                                 max_pooling2d[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_8 (LeakyReLU)       (None, 24, 24, 768)  0           concatenate_1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2D)  (None, 12, 12, 768)  0           leaky_re_lu_8[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_10 (SeparableC (None, 12, 12, 512)  400128      max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_10 (Batc (None, 12, 12, 512)  2048        separable_conv2d_10[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_9 (LeakyReLU)       (None, 12, 12, 512)  0           batch_normalization_v1_10[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_11 (SeparableC (None, 12, 12, 1024) 528896      leaky_re_lu_9[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_11 (Batc (None, 12, 12, 1024) 4096        separable_conv2d_11[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_10 (LeakyReLU)      (None, 12, 12, 1024) 0           batch_normalization_v1_11[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_12 (SeparableC (None, 12, 12, 256)  271360      leaky_re_lu_10[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_9 (SeparableCo (None, 24, 24, 1024) 528896      max_pooling2d[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_12 (Batc (None, 12, 12, 256)  1024        separable_conv2d_12[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_9 (Batch (None, 24, 24, 1024) 4096        separable_conv2d_9[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_2 (Concatenate)     (None, 12, 12, 1024) 0           batch_normalization_v1_12[0][0]  \n",
            "                                                                 max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2D)  (None, 12, 12, 1024) 0           batch_normalization_v1_9[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_3 (Concatenate)     (None, 12, 12, 2048) 0           concatenate_2[0][0]              \n",
            "                                                                 max_pooling2d_2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_11 (LeakyReLU)      (None, 12, 12, 2048) 0           concatenate_3[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d (Conv2D)                 (None, 12, 12, 200)  409600      leaky_re_lu_11[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "global_average_pooling2d (Globa (None, 200)          0           conv2d[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation (Activation)         (None, 200)          0           global_average_pooling2d[0][0]   \n",
            "==================================================================================================\n",
            "Total params: 4,209,819\n",
            "Trainable params: 4,196,123\n",
            "Non-trainable params: 13,696\n",
            "__________________________________________________________________________________________________\n",
            "Found 100000 images belonging to 200 classes.\n",
            "Found 10000 images belonging to 200 classes.\n",
            "Epoch 101/150\n",
            "INFO:tensorflow:New input shapes; (re-)compiling: mode=train (# of cores 8), [TensorSpec(shape=(128,), dtype=tf.int32, name='core_id0'), TensorSpec(shape=(128, 48, 48, 3), dtype=tf.float32, name='input_1_10'), TensorSpec(shape=(128, 200), dtype=tf.float32, name='activation_target_30')]\n",
            "INFO:tensorflow:Overriding default placeholder.\n",
            "INFO:tensorflow:Remapping placeholder for input_1\n",
            "INFO:tensorflow:Started compiling\n",
            "INFO:tensorflow:Finished compiling. Time elapsed: 30.926091194152832 secs\n",
            "INFO:tensorflow:Setting weights on TPU model.\n",
            "96/97 [============================>.] - ETA: 3s - loss: 2.2475 - acc: 0.4653INFO:tensorflow:New input shapes; (re-)compiling: mode=eval (# of cores 8), [TensorSpec(shape=(128,), dtype=tf.int32, name='core_id_10'), TensorSpec(shape=(128, 48, 48, 3), dtype=tf.float32, name='input_1_10'), TensorSpec(shape=(128, 200), dtype=tf.float32, name='activation_target_30')]\n",
            "INFO:tensorflow:Overriding default placeholder.\n",
            "INFO:tensorflow:Remapping placeholder for input_1\n",
            "INFO:tensorflow:Started compiling\n",
            "INFO:tensorflow:Finished compiling. Time elapsed: 6.685988426208496 secs\n",
            " 9/10 [==========================>...] - ETA: 1s - loss: 2.2813 - acc: 0.4633INFO:tensorflow:New input shapes; (re-)compiling: mode=eval (# of cores 8), [TensorSpec(shape=(98,), dtype=tf.int32, name='core_id_10'), TensorSpec(shape=(98, 48, 48, 3), dtype=tf.float32, name='input_1_10'), TensorSpec(shape=(98, 200), dtype=tf.float32, name='activation_target_30')]\n",
            "INFO:tensorflow:Overriding default placeholder.\n",
            "INFO:tensorflow:Remapping placeholder for input_1\n",
            "INFO:tensorflow:Started compiling\n",
            "INFO:tensorflow:Finished compiling. Time elapsed: 6.645446062088013 secs\n",
            "10/10 [==============================] - 21s 2s/step - loss: 2.2803 - acc: 0.4638\n",
            "INFO:tensorflow:Copying TPU weights to the CPU\n",
            "97/97 [==============================] - 356s 4s/step - loss: 2.2473 - acc: 0.4655 - val_loss: 2.2803 - val_acc: 0.4638\n",
            "Epoch 102/150\n",
            "INFO:tensorflow:New input shapes; (re-)compiling: mode=train (# of cores 8), [TensorSpec(shape=(84,), dtype=tf.int32, name='core_id0'), TensorSpec(shape=(84, 48, 48, 3), dtype=tf.float32, name='input_1_10'), TensorSpec(shape=(84, 200), dtype=tf.float32, name='activation_target_30')]\n",
            "INFO:tensorflow:Overriding default placeholder.\n",
            "INFO:tensorflow:Remapping placeholder for input_1\n",
            "INFO:tensorflow:Started compiling\n",
            "INFO:tensorflow:Finished compiling. Time elapsed: 22.614376544952393 secs\n",
            "10/10 [==============================] - 13s 1s/step - loss: 2.3377 - acc: 0.4640\n",
            "97/97 [==============================] - 283s 3s/step - loss: 2.1752 - acc: 0.4793 - val_loss: 2.3377 - val_acc: 0.4640\n",
            "Epoch 103/150\n",
            "10/10 [==============================] - 13s 1s/step - loss: 2.2338 - acc: 0.4780\n",
            "INFO:tensorflow:Copying TPU weights to the CPU\n",
            "97/97 [==============================] - 280s 3s/step - loss: 2.1302 - acc: 0.4882 - val_loss: 2.2338 - val_acc: 0.4780\n",
            "Epoch 104/150\n",
            "10/10 [==============================] - 13s 1s/step - loss: 2.2310 - acc: 0.4768\n",
            "INFO:tensorflow:Copying TPU weights to the CPU\n",
            "97/97 [==============================] - 276s 3s/step - loss: 2.0997 - acc: 0.4922 - val_loss: 2.2310 - val_acc: 0.4768\n",
            "Epoch 105/150\n",
            "10/10 [==============================] - 13s 1s/step - loss: 2.2225 - acc: 0.4842\n",
            "INFO:tensorflow:Copying TPU weights to the CPU\n",
            "97/97 [==============================] - 276s 3s/step - loss: 2.0713 - acc: 0.4977 - val_loss: 2.2225 - val_acc: 0.4842\n",
            "Epoch 106/150\n",
            "10/10 [==============================] - 14s 1s/step - loss: 2.2855 - acc: 0.4804\n",
            "97/97 [==============================] - 275s 3s/step - loss: 2.0503 - acc: 0.5023 - val_loss: 2.2855 - val_acc: 0.4804\n",
            "Epoch 107/150\n",
            "10/10 [==============================] - 13s 1s/step - loss: 2.2582 - acc: 0.4826\n",
            "97/97 [==============================] - 274s 3s/step - loss: 2.0292 - acc: 0.5055 - val_loss: 2.2582 - val_acc: 0.4826\n",
            "Epoch 108/150\n",
            "10/10 [==============================] - 14s 1s/step - loss: 2.2994 - acc: 0.4768\n",
            "97/97 [==============================] - 278s 3s/step - loss: 2.0038 - acc: 0.5105 - val_loss: 2.2994 - val_acc: 0.4768\n",
            "Epoch 109/150\n",
            "10/10 [==============================] - 14s 1s/step - loss: 2.2682 - acc: 0.4791\n",
            "97/97 [==============================] - 277s 3s/step - loss: 1.9874 - acc: 0.5153 - val_loss: 2.2682 - val_acc: 0.4791\n",
            "Epoch 110/150\n",
            "10/10 [==============================] - 14s 1s/step - loss: 2.2467 - acc: 0.4875\n",
            "97/97 [==============================] - 277s 3s/step - loss: 1.9646 - acc: 0.5201 - val_loss: 2.2467 - val_acc: 0.4875\n",
            "Epoch 111/150\n",
            "10/10 [==============================] - 14s 1s/step - loss: 2.3158 - acc: 0.4834\n",
            "97/97 [==============================] - 278s 3s/step - loss: 1.9559 - acc: 0.5206 - val_loss: 2.3158 - val_acc: 0.4834\n",
            "Epoch 112/150\n",
            "10/10 [==============================] - 13s 1s/step - loss: 2.2704 - acc: 0.4846\n",
            "97/97 [==============================] - 278s 3s/step - loss: 1.9342 - acc: 0.5248 - val_loss: 2.2704 - val_acc: 0.4846\n",
            "Epoch 113/150\n",
            "10/10 [==============================] - 14s 1s/step - loss: 2.1988 - acc: 0.4991\n",
            "INFO:tensorflow:Copying TPU weights to the CPU\n",
            "97/97 [==============================] - 281s 3s/step - loss: 1.9219 - acc: 0.5279 - val_loss: 2.1988 - val_acc: 0.4991\n",
            "Epoch 114/150\n",
            "10/10 [==============================] - 14s 1s/step - loss: 2.2390 - acc: 0.4957\n",
            "97/97 [==============================] - 276s 3s/step - loss: 1.9031 - acc: 0.5294 - val_loss: 2.2390 - val_acc: 0.4957\n",
            "Epoch 115/150\n",
            "10/10 [==============================] - 14s 1s/step - loss: 2.2745 - acc: 0.4939\n",
            "97/97 [==============================] - 278s 3s/step - loss: 1.8834 - acc: 0.5348 - val_loss: 2.2745 - val_acc: 0.4939\n",
            "Epoch 116/150\n",
            "10/10 [==============================] - 14s 1s/step - loss: 2.3549 - acc: 0.4788\n",
            "97/97 [==============================] - 277s 3s/step - loss: 1.8786 - acc: 0.5345 - val_loss: 2.3549 - val_acc: 0.4788\n",
            "Epoch 117/150\n",
            "10/10 [==============================] - 13s 1s/step - loss: 2.2762 - acc: 0.4912\n",
            "97/97 [==============================] - 275s 3s/step - loss: 1.8638 - acc: 0.5399 - val_loss: 2.2762 - val_acc: 0.4912\n",
            "Epoch 118/150\n",
            "10/10 [==============================] - 13s 1s/step - loss: 2.2646 - acc: 0.4958\n",
            "97/97 [==============================] - 277s 3s/step - loss: 1.8378 - acc: 0.5452 - val_loss: 2.2646 - val_acc: 0.4958\n",
            "Epoch 119/150\n",
            "10/10 [==============================] - 15s 1s/step - loss: 2.3992 - acc: 0.4864\n",
            "97/97 [==============================] - 278s 3s/step - loss: 1.8251 - acc: 0.5482 - val_loss: 2.3992 - val_acc: 0.4864\n",
            "Epoch 120/150\n",
            "10/10 [==============================] - 13s 1s/step - loss: 2.3578 - acc: 0.4924\n",
            "97/97 [==============================] - 273s 3s/step - loss: 1.8057 - acc: 0.5500 - val_loss: 2.3578 - val_acc: 0.4924\n",
            "Epoch 121/150\n",
            "10/10 [==============================] - 13s 1s/step - loss: 2.3683 - acc: 0.4891\n",
            "97/97 [==============================] - 275s 3s/step - loss: 1.8071 - acc: 0.5506 - val_loss: 2.3683 - val_acc: 0.4891\n",
            "Epoch 122/150\n",
            "10/10 [==============================] - 13s 1s/step - loss: 2.2989 - acc: 0.4923\n",
            "97/97 [==============================] - 276s 3s/step - loss: 1.7852 - acc: 0.5571 - val_loss: 2.2989 - val_acc: 0.4923\n",
            "Epoch 123/150\n",
            "10/10 [==============================] - 13s 1s/step - loss: 2.3971 - acc: 0.4840\n",
            "97/97 [==============================] - 277s 3s/step - loss: 1.7723 - acc: 0.5593 - val_loss: 2.3971 - val_acc: 0.4840\n",
            "Epoch 124/150\n",
            "10/10 [==============================] - 14s 1s/step - loss: 2.2977 - acc: 0.4892\n",
            "97/97 [==============================] - 278s 3s/step - loss: 1.7642 - acc: 0.5593 - val_loss: 2.2977 - val_acc: 0.4892\n",
            "Epoch 125/150\n",
            "10/10 [==============================] - 13s 1s/step - loss: 2.3800 - acc: 0.4867\n",
            "97/97 [==============================] - 276s 3s/step - loss: 1.7489 - acc: 0.5647 - val_loss: 2.3800 - val_acc: 0.4867\n",
            "Epoch 126/150\n",
            "10/10 [==============================] - 13s 1s/step - loss: 2.3408 - acc: 0.4973\n",
            "97/97 [==============================] - 276s 3s/step - loss: 1.7249 - acc: 0.5690 - val_loss: 2.3408 - val_acc: 0.4973\n",
            "Epoch 127/150\n",
            "10/10 [==============================] - 14s 1s/step - loss: 2.3912 - acc: 0.4897\n",
            "97/97 [==============================] - 276s 3s/step - loss: 1.7242 - acc: 0.5692 - val_loss: 2.3912 - val_acc: 0.4897\n",
            "Epoch 128/150\n",
            "10/10 [==============================] - 13s 1s/step - loss: 2.3919 - acc: 0.4883\n",
            "97/97 [==============================] - 274s 3s/step - loss: 1.7062 - acc: 0.5716 - val_loss: 2.3919 - val_acc: 0.4883\n",
            "Epoch 129/150\n",
            "10/10 [==============================] - 13s 1s/step - loss: 2.3460 - acc: 0.5004\n",
            "97/97 [==============================] - 276s 3s/step - loss: 1.7057 - acc: 0.5722 - val_loss: 2.3460 - val_acc: 0.5004\n",
            "Epoch 130/150\n",
            "10/10 [==============================] - 14s 1s/step - loss: 2.4250 - acc: 0.4913\n",
            "97/97 [==============================] - 277s 3s/step - loss: 1.6893 - acc: 0.5752 - val_loss: 2.4250 - val_acc: 0.4913\n",
            "Epoch 131/150\n",
            "10/10 [==============================] - 13s 1s/step - loss: 2.3283 - acc: 0.4978\n",
            "97/97 [==============================] - 276s 3s/step - loss: 1.6780 - acc: 0.5793 - val_loss: 2.3283 - val_acc: 0.4978\n",
            "Epoch 132/150\n",
            "10/10 [==============================] - 14s 1s/step - loss: 2.3966 - acc: 0.4919\n",
            "97/97 [==============================] - 273s 3s/step - loss: 1.6663 - acc: 0.5812 - val_loss: 2.3966 - val_acc: 0.4919\n",
            "Epoch 133/150\n",
            "10/10 [==============================] - 13s 1s/step - loss: 2.3512 - acc: 0.5019\n",
            "97/97 [==============================] - 272s 3s/step - loss: 1.6562 - acc: 0.5818 - val_loss: 2.3512 - val_acc: 0.5019\n",
            "Epoch 134/150\n",
            "10/10 [==============================] - 13s 1s/step - loss: 2.4070 - acc: 0.4926\n",
            "97/97 [==============================] - 275s 3s/step - loss: 1.6376 - acc: 0.5864 - val_loss: 2.4070 - val_acc: 0.4926\n",
            "Epoch 135/150\n",
            "10/10 [==============================] - 13s 1s/step - loss: 2.3600 - acc: 0.4954\n",
            "97/97 [==============================] - 272s 3s/step - loss: 1.6193 - acc: 0.5903 - val_loss: 2.3600 - val_acc: 0.4954\n",
            "Epoch 136/150\n",
            "10/10 [==============================] - 15s 1s/step - loss: 2.4086 - acc: 0.4996\n",
            "97/97 [==============================] - 274s 3s/step - loss: 1.6199 - acc: 0.5896 - val_loss: 2.4086 - val_acc: 0.4996\n",
            "Epoch 137/150\n",
            "10/10 [==============================] - 13s 1s/step - loss: 2.4743 - acc: 0.4871\n",
            "97/97 [==============================] - 273s 3s/step - loss: 1.6031 - acc: 0.5949 - val_loss: 2.4743 - val_acc: 0.4871\n",
            "Epoch 138/150\n",
            "10/10 [==============================] - 14s 1s/step - loss: 2.5025 - acc: 0.4897\n",
            "97/97 [==============================] - 276s 3s/step - loss: 1.6012 - acc: 0.5927 - val_loss: 2.5025 - val_acc: 0.4897\n",
            "Epoch 139/150\n",
            "10/10 [==============================] - 14s 1s/step - loss: 2.4165 - acc: 0.5005\n",
            "97/97 [==============================] - 275s 3s/step - loss: 1.5826 - acc: 0.5998 - val_loss: 2.4165 - val_acc: 0.5005\n",
            "Epoch 140/150\n",
            "10/10 [==============================] - 14s 1s/step - loss: 2.4869 - acc: 0.4877\n",
            "97/97 [==============================] - 275s 3s/step - loss: 1.5757 - acc: 0.5983 - val_loss: 2.4869 - val_acc: 0.4877\n",
            "Epoch 141/150\n",
            "24/97 [======>.......................] - ETA: 3:00 - loss: 1.5934 - acc: 0.5956"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5hFze8z_OyLT",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 5744
        },
        "outputId": "f2190fd1-0754-4fcf-e727-21b10fe89484"
      },
      "source": [
        "learning_strategy(image_size=64,previous_epoch=150,epoch_size=200,batchsize=512,learning_rate=0.0003)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading previous model with least val loss: /gdrive/My Drive/tpuweights/vddddAssignment4Amodel_113_2.20.hdf5\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n",
            "\n",
            "WARNING: The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
            "For more information, please see:\n",
            "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
            "  * https://github.com/tensorflow/addons\n",
            "If you depend on functionality not listed there, please file an issue.\n",
            "\n",
            "INFO:tensorflow:Querying Tensorflow master (grpc://10.43.40.34:8470) for TPU system metadata.\n",
            "INFO:tensorflow:Found TPU system:\n",
            "INFO:tensorflow:*** Num TPU Cores: 8\n",
            "INFO:tensorflow:*** Num TPU Workers: 1\n",
            "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, -1, 11008659628945883540)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 17179869184, 5181798764399224991)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 17179869184, 3432038368502799491)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 17179869184, 16660559128391391789)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 17179869184, 12700260637731669900)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 17179869184, 15863487362165671274)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 17179869184, 8701504139632149146)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 17179869184, 4640564718040258917)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 17179869184, 16467353907345433737)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 17179869184, 5281757979726512854)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 17179869184, 601997231931482932)\n",
            "WARNING:tensorflow:tpu_model (from tensorflow.contrib.tpu.python.tpu.keras_support) is experimental and may change or be removed at any time, and without warning.\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            (None, 64, 64, 3)    0                                            \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d (SeparableConv (None, 64, 64, 64)   219         input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1 (BatchNo (None, 64, 64, 64)   256         separable_conv2d[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu (LeakyReLU)         (None, 64, 64, 64)   0           batch_normalization_v1[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_1 (SeparableCo (None, 64, 64, 128)  8768        leaky_re_lu[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_1 (Batch (None, 64, 64, 128)  512         separable_conv2d_1[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_1 (LeakyReLU)       (None, 64, 64, 128)  0           batch_normalization_v1_1[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_2 (SeparableCo (None, 64, 64, 256)  33920       leaky_re_lu_1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_2 (Batch (None, 64, 64, 256)  1024        separable_conv2d_2[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_2 (LeakyReLU)       (None, 64, 64, 256)  0           batch_normalization_v1_2[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_3 (SeparableCo (None, 64, 64, 512)  133376      leaky_re_lu_2[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_3 (Batch (None, 64, 64, 512)  2048        separable_conv2d_3[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_3 (LeakyReLU)       (None, 64, 64, 512)  0           batch_normalization_v1_3[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_4 (SeparableCo (None, 64, 64, 1024) 528896      leaky_re_lu_3[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_4 (Batch (None, 64, 64, 1024) 4096        separable_conv2d_4[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_4 (LeakyReLU)       (None, 64, 64, 1024) 0           batch_normalization_v1_4[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_5 (SeparableCo (None, 64, 64, 256)  271360      leaky_re_lu_4[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_5 (Batch (None, 64, 64, 256)  1024        separable_conv2d_5[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "concatenate (Concatenate)       (None, 64, 64, 512)  0           batch_normalization_v1_5[0][0]   \n",
            "                                                                 leaky_re_lu_2[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_5 (LeakyReLU)       (None, 64, 64, 512)  0           concatenate[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D)    (None, 32, 32, 512)  0           leaky_re_lu_5[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_6 (SeparableCo (None, 32, 32, 512)  266752      max_pooling2d[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_6 (Batch (None, 32, 32, 512)  2048        separable_conv2d_6[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_6 (LeakyReLU)       (None, 32, 32, 512)  0           batch_normalization_v1_6[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_7 (SeparableCo (None, 32, 32, 1024) 528896      leaky_re_lu_6[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_7 (Batch (None, 32, 32, 1024) 4096        separable_conv2d_7[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_7 (LeakyReLU)       (None, 32, 32, 1024) 0           batch_normalization_v1_7[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_8 (SeparableCo (None, 32, 32, 256)  271360      leaky_re_lu_7[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_8 (Batch (None, 32, 32, 256)  1024        separable_conv2d_8[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_1 (Concatenate)     (None, 32, 32, 768)  0           batch_normalization_v1_8[0][0]   \n",
            "                                                                 max_pooling2d[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_8 (LeakyReLU)       (None, 32, 32, 768)  0           concatenate_1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2D)  (None, 16, 16, 768)  0           leaky_re_lu_8[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_10 (SeparableC (None, 16, 16, 512)  400128      max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_10 (Batc (None, 16, 16, 512)  2048        separable_conv2d_10[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_9 (LeakyReLU)       (None, 16, 16, 512)  0           batch_normalization_v1_10[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_11 (SeparableC (None, 16, 16, 1024) 528896      leaky_re_lu_9[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_11 (Batc (None, 16, 16, 1024) 4096        separable_conv2d_11[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_10 (LeakyReLU)      (None, 16, 16, 1024) 0           batch_normalization_v1_11[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_12 (SeparableC (None, 16, 16, 256)  271360      leaky_re_lu_10[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_9 (SeparableCo (None, 32, 32, 1024) 528896      max_pooling2d[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_12 (Batc (None, 16, 16, 256)  1024        separable_conv2d_12[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_9 (Batch (None, 32, 32, 1024) 4096        separable_conv2d_9[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_2 (Concatenate)     (None, 16, 16, 1024) 0           batch_normalization_v1_12[0][0]  \n",
            "                                                                 max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2D)  (None, 16, 16, 1024) 0           batch_normalization_v1_9[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_3 (Concatenate)     (None, 16, 16, 2048) 0           concatenate_2[0][0]              \n",
            "                                                                 max_pooling2d_2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_11 (LeakyReLU)      (None, 16, 16, 2048) 0           concatenate_3[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d (Conv2D)                 (None, 16, 16, 200)  409600      leaky_re_lu_11[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "global_average_pooling2d (Globa (None, 200)          0           conv2d[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation (Activation)         (None, 200)          0           global_average_pooling2d[0][0]   \n",
            "==================================================================================================\n",
            "Total params: 4,209,819\n",
            "Trainable params: 4,196,123\n",
            "Non-trainable params: 13,696\n",
            "__________________________________________________________________________________________________\n",
            "Found 100000 images belonging to 200 classes.\n",
            "Found 10000 images belonging to 200 classes.\n",
            "Epoch 151/200\n",
            "INFO:tensorflow:New input shapes; (re-)compiling: mode=train (# of cores 8), [TensorSpec(shape=(64,), dtype=tf.int32, name='core_id0'), TensorSpec(shape=(64, 64, 64, 3), dtype=tf.float32, name='input_1_10'), TensorSpec(shape=(64, 200), dtype=tf.float32, name='activation_target_30')]\n",
            "INFO:tensorflow:Overriding default placeholder.\n",
            "INFO:tensorflow:Remapping placeholder for input_1\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/tpu/python/tpu/keras_support.py:302: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "INFO:tensorflow:Started compiling\n",
            "INFO:tensorflow:Finished compiling. Time elapsed: 31.05174946784973 secs\n",
            "INFO:tensorflow:Setting weights on TPU model.\n",
            "194/195 [============================>.] - ETA: 2s - loss: 1.9811 - acc: 0.5233INFO:tensorflow:New input shapes; (re-)compiling: mode=eval (# of cores 8), [TensorSpec(shape=(64,), dtype=tf.int32, name='core_id_10'), TensorSpec(shape=(64, 64, 64, 3), dtype=tf.float32, name='input_1_10'), TensorSpec(shape=(64, 200), dtype=tf.float32, name='activation_target_30')]\n",
            "INFO:tensorflow:Overriding default placeholder.\n",
            "INFO:tensorflow:Remapping placeholder for input_1\n",
            "INFO:tensorflow:Started compiling\n",
            "INFO:tensorflow:Finished compiling. Time elapsed: 6.1006410121917725 secs\n",
            "19/20 [===========================>..] - ETA: 0s - loss: 2.1391 - acc: 0.5011INFO:tensorflow:New input shapes; (re-)compiling: mode=eval (# of cores 8), [TensorSpec(shape=(34,), dtype=tf.int32, name='core_id_10'), TensorSpec(shape=(34, 64, 64, 3), dtype=tf.float32, name='input_1_10'), TensorSpec(shape=(34, 200), dtype=tf.float32, name='activation_target_30')]\n",
            "INFO:tensorflow:Overriding default placeholder.\n",
            "INFO:tensorflow:Remapping placeholder for input_1\n",
            "INFO:tensorflow:Started compiling\n",
            "INFO:tensorflow:Finished compiling. Time elapsed: 6.274145603179932 secs\n",
            "20/20 [==============================] - 24s 1s/step - loss: 2.1447 - acc: 0.5011\n",
            "INFO:tensorflow:Copying TPU weights to the CPU\n",
            "195/195 [==============================] - 492s 3s/step - loss: 1.9806 - acc: 0.5235 - val_loss: 2.1447 - val_acc: 0.5011\n",
            "Epoch 152/200\n",
            "INFO:tensorflow:New input shapes; (re-)compiling: mode=train (# of cores 8), [TensorSpec(shape=(20,), dtype=tf.int32, name='core_id0'), TensorSpec(shape=(20, 64, 64, 3), dtype=tf.float32, name='input_1_10'), TensorSpec(shape=(20, 200), dtype=tf.float32, name='activation_target_30')]\n",
            "INFO:tensorflow:Overriding default placeholder.\n",
            "INFO:tensorflow:Remapping placeholder for input_1\n",
            "INFO:tensorflow:Started compiling\n",
            "INFO:tensorflow:Finished compiling. Time elapsed: 26.94033145904541 secs\n",
            "20/20 [==============================] - 14s 699ms/step - loss: 2.0926 - acc: 0.5095\n",
            "INFO:tensorflow:Copying TPU weights to the CPU\n",
            "195/195 [==============================] - 446s 2s/step - loss: 1.9164 - acc: 0.5332 - val_loss: 2.0926 - val_acc: 0.5095\n",
            "Epoch 153/200\n",
            "20/20 [==============================] - 15s 748ms/step - loss: 2.0389 - acc: 0.5188\n",
            "INFO:tensorflow:Copying TPU weights to the CPU\n",
            "195/195 [==============================] - 430s 2s/step - loss: 1.8936 - acc: 0.5378 - val_loss: 2.0389 - val_acc: 0.5188\n",
            "Epoch 154/200\n",
            "20/20 [==============================] - 14s 690ms/step - loss: 2.0572 - acc: 0.5239\n",
            "195/195 [==============================] - 426s 2s/step - loss: 1.8641 - acc: 0.5441 - val_loss: 2.0572 - val_acc: 0.5239\n",
            "Epoch 155/200\n",
            "20/20 [==============================] - 14s 722ms/step - loss: 2.0433 - acc: 0.5265\n",
            "195/195 [==============================] - 429s 2s/step - loss: 1.8460 - acc: 0.5480 - val_loss: 2.0433 - val_acc: 0.5265\n",
            "Epoch 156/200\n",
            "20/20 [==============================] - 14s 695ms/step - loss: 2.0905 - acc: 0.5158\n",
            "195/195 [==============================] - 429s 2s/step - loss: 1.8273 - acc: 0.5518 - val_loss: 2.0905 - val_acc: 0.5158\n",
            "Epoch 157/200\n",
            "20/20 [==============================] - 14s 686ms/step - loss: 2.1141 - acc: 0.5175\n",
            "195/195 [==============================] - 431s 2s/step - loss: 1.8124 - acc: 0.5536 - val_loss: 2.1141 - val_acc: 0.5175\n",
            "Epoch 158/200\n",
            "20/20 [==============================] - 14s 678ms/step - loss: 2.0285 - acc: 0.5281\n",
            "INFO:tensorflow:Copying TPU weights to the CPU\n",
            "195/195 [==============================] - 431s 2s/step - loss: 1.7948 - acc: 0.5585 - val_loss: 2.0285 - val_acc: 0.5281\n",
            "Epoch 159/200\n",
            "20/20 [==============================] - 14s 696ms/step - loss: 2.1116 - acc: 0.5186\n",
            "195/195 [==============================] - 424s 2s/step - loss: 1.7810 - acc: 0.5602 - val_loss: 2.1116 - val_acc: 0.5186\n",
            "Epoch 160/200\n",
            "20/20 [==============================] - 14s 682ms/step - loss: 2.0593 - acc: 0.5307\n",
            "195/195 [==============================] - 431s 2s/step - loss: 1.7644 - acc: 0.5644 - val_loss: 2.0593 - val_acc: 0.5307\n",
            "Epoch 161/200\n",
            "20/20 [==============================] - 14s 696ms/step - loss: 2.0796 - acc: 0.5229\n",
            "195/195 [==============================] - 430s 2s/step - loss: 1.7409 - acc: 0.5692 - val_loss: 2.0796 - val_acc: 0.5229\n",
            "Epoch 162/200\n",
            "20/20 [==============================] - 14s 683ms/step - loss: 2.1018 - acc: 0.5213\n",
            "195/195 [==============================] - 430s 2s/step - loss: 1.7346 - acc: 0.5693 - val_loss: 2.1018 - val_acc: 0.5213\n",
            "Epoch 163/200\n",
            "20/20 [==============================] - 14s 703ms/step - loss: 2.0924 - acc: 0.5239\n",
            "195/195 [==============================] - 427s 2s/step - loss: 1.7236 - acc: 0.5724 - val_loss: 2.0924 - val_acc: 0.5239\n",
            "Epoch 164/200\n",
            "20/20 [==============================] - 14s 684ms/step - loss: 2.0782 - acc: 0.5296\n",
            "195/195 [==============================] - 426s 2s/step - loss: 1.7036 - acc: 0.5747 - val_loss: 2.0782 - val_acc: 0.5296\n",
            "Epoch 165/200\n",
            "20/20 [==============================] - 14s 687ms/step - loss: 2.1303 - acc: 0.5292\n",
            "195/195 [==============================] - 429s 2s/step - loss: 1.7026 - acc: 0.5749 - val_loss: 2.1303 - val_acc: 0.5292\n",
            "Epoch 166/200\n",
            "20/20 [==============================] - 14s 692ms/step - loss: 2.0424 - acc: 0.5450\n",
            "195/195 [==============================] - 429s 2s/step - loss: 1.6834 - acc: 0.5803 - val_loss: 2.0424 - val_acc: 0.5450\n",
            "Epoch 167/200\n",
            "20/20 [==============================] - 13s 668ms/step - loss: 2.0023 - acc: 0.5435\n",
            "INFO:tensorflow:Copying TPU weights to the CPU\n",
            "195/195 [==============================] - 429s 2s/step - loss: 1.6752 - acc: 0.5827 - val_loss: 2.0023 - val_acc: 0.5435\n",
            "Epoch 168/200\n",
            "20/20 [==============================] - 14s 686ms/step - loss: 2.0704 - acc: 0.5403\n",
            "195/195 [==============================] - 423s 2s/step - loss: 1.6556 - acc: 0.5851 - val_loss: 2.0704 - val_acc: 0.5403\n",
            "Epoch 169/200\n",
            "20/20 [==============================] - 14s 695ms/step - loss: 2.0920 - acc: 0.5299\n",
            "195/195 [==============================] - 426s 2s/step - loss: 1.6484 - acc: 0.5882 - val_loss: 2.0920 - val_acc: 0.5299\n",
            "Epoch 170/200\n",
            "20/20 [==============================] - 14s 680ms/step - loss: 2.0684 - acc: 0.5424\n",
            "195/195 [==============================] - 426s 2s/step - loss: 1.6395 - acc: 0.5879 - val_loss: 2.0684 - val_acc: 0.5424\n",
            "Epoch 171/200\n",
            "20/20 [==============================] - 14s 679ms/step - loss: 2.0887 - acc: 0.5366\n",
            "195/195 [==============================] - 428s 2s/step - loss: 1.6282 - acc: 0.5910 - val_loss: 2.0887 - val_acc: 0.5366\n",
            "Epoch 172/200\n",
            "20/20 [==============================] - 14s 699ms/step - loss: 2.0739 - acc: 0.5434\n",
            "195/195 [==============================] - 425s 2s/step - loss: 1.6186 - acc: 0.5946 - val_loss: 2.0739 - val_acc: 0.5434\n",
            "Epoch 173/200\n",
            "20/20 [==============================] - 14s 686ms/step - loss: 2.0964 - acc: 0.5374\n",
            "195/195 [==============================] - 426s 2s/step - loss: 1.6036 - acc: 0.5972 - val_loss: 2.0964 - val_acc: 0.5374\n",
            "Epoch 174/200\n",
            "20/20 [==============================] - 13s 674ms/step - loss: 2.1775 - acc: 0.5241\n",
            "195/195 [==============================] - 427s 2s/step - loss: 1.5966 - acc: 0.6001 - val_loss: 2.1775 - val_acc: 0.5241\n",
            "Epoch 175/200\n",
            "20/20 [==============================] - 14s 683ms/step - loss: 2.1854 - acc: 0.5321\n",
            "195/195 [==============================] - 430s 2s/step - loss: 1.5904 - acc: 0.6002 - val_loss: 2.1854 - val_acc: 0.5321\n",
            "Epoch 176/200\n",
            "20/20 [==============================] - 14s 677ms/step - loss: 2.1065 - acc: 0.5342\n",
            "195/195 [==============================] - 426s 2s/step - loss: 1.5799 - acc: 0.6024 - val_loss: 2.1065 - val_acc: 0.5342\n",
            "Epoch 177/200\n",
            "20/20 [==============================] - 14s 708ms/step - loss: 2.1115 - acc: 0.5384\n",
            "195/195 [==============================] - 427s 2s/step - loss: 1.5773 - acc: 0.6025 - val_loss: 2.1115 - val_acc: 0.5384\n",
            "Epoch 178/200\n",
            "20/20 [==============================] - 14s 677ms/step - loss: 2.1172 - acc: 0.5329\n",
            "195/195 [==============================] - 429s 2s/step - loss: 1.5631 - acc: 0.6062 - val_loss: 2.1172 - val_acc: 0.5329\n",
            "Epoch 179/200\n",
            "20/20 [==============================] - 14s 676ms/step - loss: 2.1569 - acc: 0.5339\n",
            "195/195 [==============================] - 428s 2s/step - loss: 1.5462 - acc: 0.6085 - val_loss: 2.1569 - val_acc: 0.5339\n",
            "Epoch 180/200\n",
            "20/20 [==============================] - 14s 702ms/step - loss: 2.2355 - acc: 0.5241\n",
            "195/195 [==============================] - 431s 2s/step - loss: 1.5354 - acc: 0.6113 - val_loss: 2.2355 - val_acc: 0.5241\n",
            "Epoch 181/200\n",
            "20/20 [==============================] - 14s 680ms/step - loss: 2.1111 - acc: 0.5347\n",
            "195/195 [==============================] - 429s 2s/step - loss: 1.5295 - acc: 0.6130 - val_loss: 2.1111 - val_acc: 0.5347\n",
            "Epoch 182/200\n",
            "20/20 [==============================] - 14s 685ms/step - loss: 2.1319 - acc: 0.5425\n",
            "195/195 [==============================] - 426s 2s/step - loss: 1.5277 - acc: 0.6140 - val_loss: 2.1319 - val_acc: 0.5425\n",
            "Epoch 183/200\n",
            "20/20 [==============================] - 14s 678ms/step - loss: 2.1323 - acc: 0.5444\n",
            "195/195 [==============================] - 430s 2s/step - loss: 1.5129 - acc: 0.6174 - val_loss: 2.1323 - val_acc: 0.5444\n",
            "Epoch 184/200\n",
            "20/20 [==============================] - 14s 683ms/step - loss: 2.1079 - acc: 0.5471\n",
            "195/195 [==============================] - 427s 2s/step - loss: 1.5019 - acc: 0.6183 - val_loss: 2.1079 - val_acc: 0.5471\n",
            "Epoch 185/200\n",
            "20/20 [==============================] - 14s 702ms/step - loss: 2.1721 - acc: 0.5326\n",
            "195/195 [==============================] - 427s 2s/step - loss: 1.4941 - acc: 0.6212 - val_loss: 2.1721 - val_acc: 0.5326\n",
            "Epoch 186/200\n",
            "20/20 [==============================] - 14s 682ms/step - loss: 2.2256 - acc: 0.5306\n",
            "195/195 [==============================] - 427s 2s/step - loss: 1.4815 - acc: 0.6245 - val_loss: 2.2256 - val_acc: 0.5306\n",
            "Epoch 187/200\n",
            "20/20 [==============================] - 14s 682ms/step - loss: 2.2367 - acc: 0.5279\n",
            "195/195 [==============================] - 428s 2s/step - loss: 1.4859 - acc: 0.6228 - val_loss: 2.2367 - val_acc: 0.5279\n",
            "Epoch 188/200\n",
            "20/20 [==============================] - 14s 678ms/step - loss: 2.1405 - acc: 0.5403\n",
            "195/195 [==============================] - 430s 2s/step - loss: 1.4660 - acc: 0.6278 - val_loss: 2.1405 - val_acc: 0.5403\n",
            "Epoch 189/200\n",
            "20/20 [==============================] - 14s 683ms/step - loss: 2.2300 - acc: 0.5386\n",
            "195/195 [==============================] - 426s 2s/step - loss: 1.4541 - acc: 0.6278 - val_loss: 2.2300 - val_acc: 0.5386\n",
            "Epoch 190/200\n",
            "20/20 [==============================] - 14s 681ms/step - loss: 2.2240 - acc: 0.5356\n",
            "195/195 [==============================] - 426s 2s/step - loss: 1.4501 - acc: 0.6307 - val_loss: 2.2240 - val_acc: 0.5356\n",
            "Epoch 191/200\n",
            "20/20 [==============================] - 14s 700ms/step - loss: 2.1645 - acc: 0.5445\n",
            "195/195 [==============================] - 431s 2s/step - loss: 1.4328 - acc: 0.6336 - val_loss: 2.1645 - val_acc: 0.5445\n",
            "Epoch 192/200\n",
            "20/20 [==============================] - 14s 683ms/step - loss: 2.1827 - acc: 0.5413\n",
            "195/195 [==============================] - 430s 2s/step - loss: 1.4383 - acc: 0.6322 - val_loss: 2.1827 - val_acc: 0.5413\n",
            "Epoch 193/200\n",
            "20/20 [==============================] - 14s 710ms/step - loss: 2.2825 - acc: 0.5339\n",
            "195/195 [==============================] - 428s 2s/step - loss: 1.4204 - acc: 0.6358 - val_loss: 2.2825 - val_acc: 0.5339\n",
            "Epoch 194/200\n",
            "20/20 [==============================] - 14s 692ms/step - loss: 2.1971 - acc: 0.5444\n",
            "195/195 [==============================] - 428s 2s/step - loss: 1.4264 - acc: 0.6364 - val_loss: 2.1971 - val_acc: 0.5444\n",
            "Epoch 195/200\n",
            "20/20 [==============================] - 14s 712ms/step - loss: 2.1668 - acc: 0.5460\n",
            "195/195 [==============================] - 430s 2s/step - loss: 1.4133 - acc: 0.6386 - val_loss: 2.1668 - val_acc: 0.5460\n",
            "Epoch 196/200\n",
            "20/20 [==============================] - 14s 684ms/step - loss: 2.2253 - acc: 0.5430\n",
            "195/195 [==============================] - 428s 2s/step - loss: 1.4122 - acc: 0.6387 - val_loss: 2.2253 - val_acc: 0.5430\n",
            "Epoch 197/200\n",
            "20/20 [==============================] - 14s 687ms/step - loss: 2.2110 - acc: 0.5418\n",
            "195/195 [==============================] - 428s 2s/step - loss: 1.3969 - acc: 0.6424 - val_loss: 2.2110 - val_acc: 0.5418\n",
            "Epoch 198/200\n",
            "20/20 [==============================] - 14s 682ms/step - loss: 2.2644 - acc: 0.5372\n",
            "195/195 [==============================] - 427s 2s/step - loss: 1.3786 - acc: 0.6465 - val_loss: 2.2644 - val_acc: 0.5372\n",
            "Epoch 199/200\n",
            "20/20 [==============================] - 14s 684ms/step - loss: 2.1649 - acc: 0.5421\n",
            "195/195 [==============================] - 428s 2s/step - loss: 1.3819 - acc: 0.6465 - val_loss: 2.1649 - val_acc: 0.5421\n",
            "Epoch 200/200\n",
            "20/20 [==============================] - 14s 705ms/step - loss: 2.2403 - acc: 0.5351\n",
            "195/195 [==============================] - 428s 2s/step - loss: 1.3765 - acc: 0.6461 - val_loss: 2.2403 - val_acc: 0.5351\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_94znPGVO1IJ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 5050
        },
        "outputId": "7a9efdd6-9c7e-463a-e77b-4fa9cb5a73d9"
      },
      "source": [
        "learning_strategy(image_size=64,previous_epoch=200,epoch_size=250,batchsize=512,learning_rate=0.0001)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading previous model with least val loss: /gdrive/My Drive/tpuweights/vddddAssignment4Amodel_167_2.00.hdf5\n",
            "INFO:tensorflow:Querying Tensorflow master (grpc://10.43.40.34:8470) for TPU system metadata.\n",
            "INFO:tensorflow:Found TPU system:\n",
            "INFO:tensorflow:*** Num TPU Cores: 8\n",
            "INFO:tensorflow:*** Num TPU Workers: 1\n",
            "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, -1, 11008659628945883540)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 17179869184, 5181798764399224991)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 17179869184, 3432038368502799491)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 17179869184, 16660559128391391789)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 17179869184, 12700260637731669900)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 17179869184, 15863487362165671274)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 17179869184, 8701504139632149146)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 17179869184, 4640564718040258917)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 17179869184, 16467353907345433737)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 17179869184, 5281757979726512854)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 17179869184, 601997231931482932)\n",
            "WARNING:tensorflow:tpu_model (from tensorflow.contrib.tpu.python.tpu.keras_support) is experimental and may change or be removed at any time, and without warning.\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            (None, 64, 64, 3)    0                                            \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d (SeparableConv (None, 64, 64, 64)   219         input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1 (BatchNo (None, 64, 64, 64)   256         separable_conv2d[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu (LeakyReLU)         (None, 64, 64, 64)   0           batch_normalization_v1[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_1 (SeparableCo (None, 64, 64, 128)  8768        leaky_re_lu[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_1 (Batch (None, 64, 64, 128)  512         separable_conv2d_1[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_1 (LeakyReLU)       (None, 64, 64, 128)  0           batch_normalization_v1_1[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_2 (SeparableCo (None, 64, 64, 256)  33920       leaky_re_lu_1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_2 (Batch (None, 64, 64, 256)  1024        separable_conv2d_2[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_2 (LeakyReLU)       (None, 64, 64, 256)  0           batch_normalization_v1_2[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_3 (SeparableCo (None, 64, 64, 512)  133376      leaky_re_lu_2[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_3 (Batch (None, 64, 64, 512)  2048        separable_conv2d_3[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_3 (LeakyReLU)       (None, 64, 64, 512)  0           batch_normalization_v1_3[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_4 (SeparableCo (None, 64, 64, 1024) 528896      leaky_re_lu_3[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_4 (Batch (None, 64, 64, 1024) 4096        separable_conv2d_4[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_4 (LeakyReLU)       (None, 64, 64, 1024) 0           batch_normalization_v1_4[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_5 (SeparableCo (None, 64, 64, 256)  271360      leaky_re_lu_4[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_5 (Batch (None, 64, 64, 256)  1024        separable_conv2d_5[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "concatenate (Concatenate)       (None, 64, 64, 512)  0           batch_normalization_v1_5[0][0]   \n",
            "                                                                 leaky_re_lu_2[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_5 (LeakyReLU)       (None, 64, 64, 512)  0           concatenate[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D)    (None, 32, 32, 512)  0           leaky_re_lu_5[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_6 (SeparableCo (None, 32, 32, 512)  266752      max_pooling2d[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_6 (Batch (None, 32, 32, 512)  2048        separable_conv2d_6[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_6 (LeakyReLU)       (None, 32, 32, 512)  0           batch_normalization_v1_6[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_7 (SeparableCo (None, 32, 32, 1024) 528896      leaky_re_lu_6[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_7 (Batch (None, 32, 32, 1024) 4096        separable_conv2d_7[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_7 (LeakyReLU)       (None, 32, 32, 1024) 0           batch_normalization_v1_7[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_8 (SeparableCo (None, 32, 32, 256)  271360      leaky_re_lu_7[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_8 (Batch (None, 32, 32, 256)  1024        separable_conv2d_8[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_1 (Concatenate)     (None, 32, 32, 768)  0           batch_normalization_v1_8[0][0]   \n",
            "                                                                 max_pooling2d[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_8 (LeakyReLU)       (None, 32, 32, 768)  0           concatenate_1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2D)  (None, 16, 16, 768)  0           leaky_re_lu_8[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_10 (SeparableC (None, 16, 16, 512)  400128      max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_10 (Batc (None, 16, 16, 512)  2048        separable_conv2d_10[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_9 (LeakyReLU)       (None, 16, 16, 512)  0           batch_normalization_v1_10[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_11 (SeparableC (None, 16, 16, 1024) 528896      leaky_re_lu_9[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_11 (Batc (None, 16, 16, 1024) 4096        separable_conv2d_11[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_10 (LeakyReLU)      (None, 16, 16, 1024) 0           batch_normalization_v1_11[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_12 (SeparableC (None, 16, 16, 256)  271360      leaky_re_lu_10[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_9 (SeparableCo (None, 32, 32, 1024) 528896      max_pooling2d[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_12 (Batc (None, 16, 16, 256)  1024        separable_conv2d_12[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_9 (Batch (None, 32, 32, 1024) 4096        separable_conv2d_9[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_2 (Concatenate)     (None, 16, 16, 1024) 0           batch_normalization_v1_12[0][0]  \n",
            "                                                                 max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2D)  (None, 16, 16, 1024) 0           batch_normalization_v1_9[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_3 (Concatenate)     (None, 16, 16, 2048) 0           concatenate_2[0][0]              \n",
            "                                                                 max_pooling2d_2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_11 (LeakyReLU)      (None, 16, 16, 2048) 0           concatenate_3[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d (Conv2D)                 (None, 16, 16, 200)  409600      leaky_re_lu_11[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "global_average_pooling2d (Globa (None, 200)          0           conv2d[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation (Activation)         (None, 200)          0           global_average_pooling2d[0][0]   \n",
            "==================================================================================================\n",
            "Total params: 4,209,819\n",
            "Trainable params: 4,196,123\n",
            "Non-trainable params: 13,696\n",
            "__________________________________________________________________________________________________\n",
            "Found 100000 images belonging to 200 classes.\n",
            "Found 10000 images belonging to 200 classes.\n",
            "Epoch 201/250\n",
            "INFO:tensorflow:New input shapes; (re-)compiling: mode=train (# of cores 8), [TensorSpec(shape=(64,), dtype=tf.int32, name='core_id0'), TensorSpec(shape=(64, 64, 64, 3), dtype=tf.float32, name='input_1_10'), TensorSpec(shape=(64, 200), dtype=tf.float32, name='activation_target_30')]\n",
            "INFO:tensorflow:Overriding default placeholder.\n",
            "INFO:tensorflow:Remapping placeholder for input_1\n",
            "INFO:tensorflow:Started compiling\n",
            "INFO:tensorflow:Finished compiling. Time elapsed: 33.11345291137695 secs\n",
            "INFO:tensorflow:Setting weights on TPU model.\n",
            "194/195 [============================>.] - ETA: 2s - loss: 1.5612 - acc: 0.6114INFO:tensorflow:New input shapes; (re-)compiling: mode=eval (# of cores 8), [TensorSpec(shape=(64,), dtype=tf.int32, name='core_id_10'), TensorSpec(shape=(64, 64, 64, 3), dtype=tf.float32, name='input_1_10'), TensorSpec(shape=(64, 200), dtype=tf.float32, name='activation_target_30')]\n",
            "INFO:tensorflow:Overriding default placeholder.\n",
            "INFO:tensorflow:Remapping placeholder for input_1\n",
            "INFO:tensorflow:Started compiling\n",
            "INFO:tensorflow:Finished compiling. Time elapsed: 6.090965747833252 secs\n",
            "19/20 [===========================>..] - ETA: 0s - loss: 1.9987 - acc: 0.5485INFO:tensorflow:New input shapes; (re-)compiling: mode=eval (# of cores 8), [TensorSpec(shape=(34,), dtype=tf.int32, name='core_id_10'), TensorSpec(shape=(34, 64, 64, 3), dtype=tf.float32, name='input_1_10'), TensorSpec(shape=(34, 200), dtype=tf.float32, name='activation_target_30')]\n",
            "INFO:tensorflow:Overriding default placeholder.\n",
            "INFO:tensorflow:Remapping placeholder for input_1\n",
            "INFO:tensorflow:Started compiling\n",
            "INFO:tensorflow:Finished compiling. Time elapsed: 6.324289083480835 secs\n",
            "20/20 [==============================] - 23s 1s/step - loss: 2.0033 - acc: 0.5487\n",
            "INFO:tensorflow:Copying TPU weights to the CPU\n",
            "195/195 [==============================] - 494s 3s/step - loss: 1.5608 - acc: 0.6114 - val_loss: 2.0033 - val_acc: 0.5487\n",
            "Epoch 202/250\n",
            "INFO:tensorflow:New input shapes; (re-)compiling: mode=train (# of cores 8), [TensorSpec(shape=(20,), dtype=tf.int32, name='core_id0'), TensorSpec(shape=(20, 64, 64, 3), dtype=tf.float32, name='input_1_10'), TensorSpec(shape=(20, 200), dtype=tf.float32, name='activation_target_30')]\n",
            "INFO:tensorflow:Overriding default placeholder.\n",
            "INFO:tensorflow:Remapping placeholder for input_1\n",
            "INFO:tensorflow:Started compiling\n",
            "INFO:tensorflow:Finished compiling. Time elapsed: 25.587212800979614 secs\n",
            "20/20 [==============================] - 14s 713ms/step - loss: 1.9873 - acc: 0.5487\n",
            "INFO:tensorflow:Copying TPU weights to the CPU\n",
            "195/195 [==============================] - 446s 2s/step - loss: 1.5371 - acc: 0.6155 - val_loss: 1.9873 - val_acc: 0.5487\n",
            "Epoch 203/250\n",
            "20/20 [==============================] - 14s 708ms/step - loss: 1.9596 - acc: 0.5537\n",
            "INFO:tensorflow:Copying TPU weights to the CPU\n",
            "195/195 [==============================] - 430s 2s/step - loss: 1.5304 - acc: 0.6179 - val_loss: 1.9596 - val_acc: 0.5537\n",
            "Epoch 204/250\n",
            "20/20 [==============================] - 14s 716ms/step - loss: 1.9786 - acc: 0.5543\n",
            "195/195 [==============================] - 427s 2s/step - loss: 1.5434 - acc: 0.6150 - val_loss: 1.9786 - val_acc: 0.5543\n",
            "Epoch 205/250\n",
            "20/20 [==============================] - 14s 713ms/step - loss: 1.9762 - acc: 0.5508\n",
            "195/195 [==============================] - 430s 2s/step - loss: 1.5342 - acc: 0.6165 - val_loss: 1.9762 - val_acc: 0.5508\n",
            "Epoch 206/250\n",
            "20/20 [==============================] - 13s 675ms/step - loss: 2.0089 - acc: 0.5503\n",
            "195/195 [==============================] - 430s 2s/step - loss: 1.5026 - acc: 0.6241 - val_loss: 2.0089 - val_acc: 0.5503\n",
            "Epoch 207/250\n",
            "20/20 [==============================] - 14s 690ms/step - loss: 1.9785 - acc: 0.5486\n",
            "195/195 [==============================] - 429s 2s/step - loss: 1.4953 - acc: 0.6281 - val_loss: 1.9785 - val_acc: 0.5486\n",
            "Epoch 208/250\n",
            "20/20 [==============================] - 15s 738ms/step - loss: 1.9818 - acc: 0.5529\n",
            "195/195 [==============================] - 428s 2s/step - loss: 1.4936 - acc: 0.6258 - val_loss: 1.9818 - val_acc: 0.5529\n",
            "Epoch 209/250\n",
            "20/20 [==============================] - 14s 684ms/step - loss: 1.9938 - acc: 0.5524\n",
            "195/195 [==============================] - 429s 2s/step - loss: 1.4826 - acc: 0.6283 - val_loss: 1.9938 - val_acc: 0.5524\n",
            "Epoch 210/250\n",
            "20/20 [==============================] - 14s 681ms/step - loss: 1.9783 - acc: 0.5571\n",
            "195/195 [==============================] - 427s 2s/step - loss: 1.4774 - acc: 0.6299 - val_loss: 1.9783 - val_acc: 0.5571\n",
            "Epoch 211/250\n",
            "20/20 [==============================] - 14s 690ms/step - loss: 1.9946 - acc: 0.5544\n",
            "195/195 [==============================] - 430s 2s/step - loss: 1.4649 - acc: 0.6327 - val_loss: 1.9946 - val_acc: 0.5544\n",
            "Epoch 212/250\n",
            "20/20 [==============================] - 14s 693ms/step - loss: 2.0142 - acc: 0.5516\n",
            "195/195 [==============================] - 430s 2s/step - loss: 1.4608 - acc: 0.6326 - val_loss: 2.0142 - val_acc: 0.5516\n",
            "Epoch 213/250\n",
            "20/20 [==============================] - 14s 686ms/step - loss: 1.9588 - acc: 0.5588\n",
            "INFO:tensorflow:Copying TPU weights to the CPU\n",
            "195/195 [==============================] - 432s 2s/step - loss: 1.4534 - acc: 0.6353 - val_loss: 1.9588 - val_acc: 0.5588\n",
            "Epoch 214/250\n",
            "20/20 [==============================] - 14s 681ms/step - loss: 1.9962 - acc: 0.5561\n",
            "195/195 [==============================] - 427s 2s/step - loss: 1.4472 - acc: 0.6362 - val_loss: 1.9962 - val_acc: 0.5561\n",
            "Epoch 215/250\n",
            "20/20 [==============================] - 14s 690ms/step - loss: 2.0325 - acc: 0.5523\n",
            "195/195 [==============================] - 427s 2s/step - loss: 1.4443 - acc: 0.6365 - val_loss: 2.0325 - val_acc: 0.5523\n",
            "Epoch 216/250\n",
            "20/20 [==============================] - 14s 688ms/step - loss: 2.0213 - acc: 0.5509\n",
            "195/195 [==============================] - 430s 2s/step - loss: 1.4407 - acc: 0.6370 - val_loss: 2.0213 - val_acc: 0.5509\n",
            "Epoch 217/250\n",
            "20/20 [==============================] - 13s 674ms/step - loss: 1.9918 - acc: 0.5556\n",
            "195/195 [==============================] - 428s 2s/step - loss: 1.4385 - acc: 0.6384 - val_loss: 1.9918 - val_acc: 0.5556\n",
            "Epoch 218/250\n",
            "20/20 [==============================] - 13s 673ms/step - loss: 2.0022 - acc: 0.5558\n",
            "195/195 [==============================] - 428s 2s/step - loss: 1.4679 - acc: 0.6301 - val_loss: 2.0022 - val_acc: 0.5558\n",
            "Epoch 219/250\n",
            "20/20 [==============================] - 14s 683ms/step - loss: 1.9998 - acc: 0.5583\n",
            "195/195 [==============================] - 432s 2s/step - loss: 1.4695 - acc: 0.6281 - val_loss: 1.9998 - val_acc: 0.5583\n",
            "Epoch 220/250\n",
            "20/20 [==============================] - 14s 685ms/step - loss: 2.0456 - acc: 0.5524\n",
            "195/195 [==============================] - 432s 2s/step - loss: 1.4631 - acc: 0.6304 - val_loss: 2.0456 - val_acc: 0.5524\n",
            "Epoch 221/250\n",
            "20/20 [==============================] - 14s 683ms/step - loss: 2.0547 - acc: 0.5512\n",
            "195/195 [==============================] - 431s 2s/step - loss: 1.4581 - acc: 0.6319 - val_loss: 2.0547 - val_acc: 0.5512\n",
            "Epoch 222/250\n",
            "20/20 [==============================] - 14s 698ms/step - loss: 2.0480 - acc: 0.5479\n",
            "195/195 [==============================] - 432s 2s/step - loss: 1.4523 - acc: 0.6331 - val_loss: 2.0480 - val_acc: 0.5479\n",
            "Epoch 223/250\n",
            "20/20 [==============================] - 14s 681ms/step - loss: 1.9948 - acc: 0.5554\n",
            "195/195 [==============================] - 428s 2s/step - loss: 1.4563 - acc: 0.6309 - val_loss: 1.9948 - val_acc: 0.5554\n",
            "Epoch 224/250\n",
            "20/20 [==============================] - 13s 672ms/step - loss: 2.0498 - acc: 0.5497\n",
            "195/195 [==============================] - 434s 2s/step - loss: 1.4460 - acc: 0.6364 - val_loss: 2.0498 - val_acc: 0.5497\n",
            "Epoch 225/250\n",
            "20/20 [==============================] - 14s 694ms/step - loss: 2.0638 - acc: 0.5490\n",
            "195/195 [==============================] - 429s 2s/step - loss: 1.4389 - acc: 0.6371 - val_loss: 2.0638 - val_acc: 0.5490\n",
            "Epoch 226/250\n",
            "20/20 [==============================] - 14s 676ms/step - loss: 2.0423 - acc: 0.5508\n",
            "195/195 [==============================] - 429s 2s/step - loss: 1.4366 - acc: 0.6378 - val_loss: 2.0423 - val_acc: 0.5508\n",
            "Epoch 227/250\n",
            "20/20 [==============================] - 14s 685ms/step - loss: 2.0252 - acc: 0.5508\n",
            "195/195 [==============================] - 430s 2s/step - loss: 1.4388 - acc: 0.6379 - val_loss: 2.0252 - val_acc: 0.5508\n",
            "Epoch 228/250\n",
            "20/20 [==============================] - 14s 685ms/step - loss: 2.0582 - acc: 0.5550\n",
            "195/195 [==============================] - 428s 2s/step - loss: 1.4275 - acc: 0.6381 - val_loss: 2.0582 - val_acc: 0.5550\n",
            "Epoch 229/250\n",
            "20/20 [==============================] - 14s 717ms/step - loss: 2.0362 - acc: 0.5533\n",
            "195/195 [==============================] - 431s 2s/step - loss: 1.4218 - acc: 0.6402 - val_loss: 2.0362 - val_acc: 0.5533\n",
            "Epoch 230/250\n",
            "20/20 [==============================] - 14s 682ms/step - loss: 2.0704 - acc: 0.5525\n",
            "195/195 [==============================] - 430s 2s/step - loss: 1.4190 - acc: 0.6385 - val_loss: 2.0704 - val_acc: 0.5525\n",
            "Epoch 231/250\n",
            "20/20 [==============================] - 14s 687ms/step - loss: 2.0276 - acc: 0.5542\n",
            "195/195 [==============================] - 428s 2s/step - loss: 1.4126 - acc: 0.6412 - val_loss: 2.0276 - val_acc: 0.5542\n",
            "Epoch 232/250\n",
            "20/20 [==============================] - 14s 684ms/step - loss: 2.0219 - acc: 0.5542\n",
            "195/195 [==============================] - 430s 2s/step - loss: 1.4196 - acc: 0.6408 - val_loss: 2.0219 - val_acc: 0.5542\n",
            "Epoch 233/250\n",
            "20/20 [==============================] - 14s 677ms/step - loss: 2.0537 - acc: 0.5527\n",
            "195/195 [==============================] - 428s 2s/step - loss: 1.4072 - acc: 0.6442 - val_loss: 2.0537 - val_acc: 0.5527\n",
            "Epoch 234/250\n",
            "20/20 [==============================] - 14s 681ms/step - loss: 2.0491 - acc: 0.5568\n",
            "195/195 [==============================] - 429s 2s/step - loss: 1.4025 - acc: 0.6434 - val_loss: 2.0491 - val_acc: 0.5568\n",
            "Epoch 235/250\n",
            "20/20 [==============================] - 14s 686ms/step - loss: 2.0942 - acc: 0.5454\n",
            "195/195 [==============================] - 430s 2s/step - loss: 1.4017 - acc: 0.6443 - val_loss: 2.0942 - val_acc: 0.5454\n",
            "Epoch 236/250\n",
            "20/20 [==============================] - 14s 683ms/step - loss: 2.0955 - acc: 0.5510\n",
            "195/195 [==============================] - 427s 2s/step - loss: 1.3902 - acc: 0.6469 - val_loss: 2.0955 - val_acc: 0.5510\n",
            "Epoch 237/250\n",
            "20/20 [==============================] - 15s 728ms/step - loss: 2.0613 - acc: 0.5522\n",
            "195/195 [==============================] - 430s 2s/step - loss: 1.3993 - acc: 0.6439 - val_loss: 2.0613 - val_acc: 0.5522\n",
            "Epoch 238/250\n",
            "20/20 [==============================] - 14s 706ms/step - loss: 2.0568 - acc: 0.5536\n",
            "195/195 [==============================] - 427s 2s/step - loss: 1.3898 - acc: 0.6468 - val_loss: 2.0568 - val_acc: 0.5536\n",
            "Epoch 239/250\n",
            "20/20 [==============================] - 14s 704ms/step - loss: 2.0666 - acc: 0.5553\n",
            "195/195 [==============================] - 427s 2s/step - loss: 1.3760 - acc: 0.6498 - val_loss: 2.0666 - val_acc: 0.5553\n",
            "Epoch 240/250\n",
            "20/20 [==============================] - 13s 670ms/step - loss: 2.1008 - acc: 0.5496\n",
            "195/195 [==============================] - 428s 2s/step - loss: 1.3782 - acc: 0.6504 - val_loss: 2.1008 - val_acc: 0.5496\n",
            "Epoch 241/250\n",
            "20/20 [==============================] - 14s 680ms/step - loss: 2.0384 - acc: 0.5610\n",
            "195/195 [==============================] - 426s 2s/step - loss: 1.3688 - acc: 0.6513 - val_loss: 2.0384 - val_acc: 0.5610\n",
            "Epoch 242/250\n",
            "20/20 [==============================] - 13s 672ms/step - loss: 2.1080 - acc: 0.5492\n",
            "195/195 [==============================] - 425s 2s/step - loss: 1.3835 - acc: 0.6483 - val_loss: 2.1080 - val_acc: 0.5492\n",
            "Epoch 243/250\n",
            "163/195 [========================>.....] - ETA: 1:07 - loss: 1.3571 - acc: 0.6541"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jKK29BJVArxd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 5726
        },
        "outputId": "8f17cc7e-7518-4653-dd57-5e1772a51345"
      },
      "source": [
        "learning_strategy(image_size=64,previous_epoch=250,epoch_size=300,batchsize=512,learning_rate=0.00006)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading previous model with least val loss: /gdrive/My Drive/tpuweights/vddddAssignment4Amodel_203_1.96.hdf5\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n",
            "\n",
            "WARNING: The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
            "For more information, please see:\n",
            "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
            "  * https://github.com/tensorflow/addons\n",
            "If you depend on functionality not listed there, please file an issue.\n",
            "\n",
            "INFO:tensorflow:Querying Tensorflow master (grpc://10.91.228.226:8470) for TPU system metadata.\n",
            "INFO:tensorflow:Found TPU system:\n",
            "INFO:tensorflow:*** Num TPU Cores: 8\n",
            "INFO:tensorflow:*** Num TPU Workers: 1\n",
            "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, -1, 7344198457844153779)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 17179869184, 6934899072856692044)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 17179869184, 2793937408538465158)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 17179869184, 13949581917199777151)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 17179869184, 13353384740771467293)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 17179869184, 12959182659396920187)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 17179869184, 14325378313217820181)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 17179869184, 6311609753862282100)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 17179869184, 2153329994498263037)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 17179869184, 8291030772692424257)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 17179869184, 5669197857916969534)\n",
            "WARNING:tensorflow:tpu_model (from tensorflow.contrib.tpu.python.tpu.keras_support) is experimental and may change or be removed at any time, and without warning.\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            (None, 64, 64, 3)    0                                            \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d (SeparableConv (None, 64, 64, 64)   219         input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1 (BatchNo (None, 64, 64, 64)   256         separable_conv2d[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu (LeakyReLU)         (None, 64, 64, 64)   0           batch_normalization_v1[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_1 (SeparableCo (None, 64, 64, 128)  8768        leaky_re_lu[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_1 (Batch (None, 64, 64, 128)  512         separable_conv2d_1[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_1 (LeakyReLU)       (None, 64, 64, 128)  0           batch_normalization_v1_1[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_2 (SeparableCo (None, 64, 64, 256)  33920       leaky_re_lu_1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_2 (Batch (None, 64, 64, 256)  1024        separable_conv2d_2[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_2 (LeakyReLU)       (None, 64, 64, 256)  0           batch_normalization_v1_2[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_3 (SeparableCo (None, 64, 64, 512)  133376      leaky_re_lu_2[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_3 (Batch (None, 64, 64, 512)  2048        separable_conv2d_3[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_3 (LeakyReLU)       (None, 64, 64, 512)  0           batch_normalization_v1_3[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_4 (SeparableCo (None, 64, 64, 1024) 528896      leaky_re_lu_3[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_4 (Batch (None, 64, 64, 1024) 4096        separable_conv2d_4[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_4 (LeakyReLU)       (None, 64, 64, 1024) 0           batch_normalization_v1_4[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_5 (SeparableCo (None, 64, 64, 256)  271360      leaky_re_lu_4[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_5 (Batch (None, 64, 64, 256)  1024        separable_conv2d_5[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "concatenate (Concatenate)       (None, 64, 64, 512)  0           batch_normalization_v1_5[0][0]   \n",
            "                                                                 leaky_re_lu_2[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_5 (LeakyReLU)       (None, 64, 64, 512)  0           concatenate[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D)    (None, 32, 32, 512)  0           leaky_re_lu_5[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_6 (SeparableCo (None, 32, 32, 512)  266752      max_pooling2d[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_6 (Batch (None, 32, 32, 512)  2048        separable_conv2d_6[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_6 (LeakyReLU)       (None, 32, 32, 512)  0           batch_normalization_v1_6[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_7 (SeparableCo (None, 32, 32, 1024) 528896      leaky_re_lu_6[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_7 (Batch (None, 32, 32, 1024) 4096        separable_conv2d_7[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_7 (LeakyReLU)       (None, 32, 32, 1024) 0           batch_normalization_v1_7[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_8 (SeparableCo (None, 32, 32, 256)  271360      leaky_re_lu_7[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_8 (Batch (None, 32, 32, 256)  1024        separable_conv2d_8[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_1 (Concatenate)     (None, 32, 32, 768)  0           batch_normalization_v1_8[0][0]   \n",
            "                                                                 max_pooling2d[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_8 (LeakyReLU)       (None, 32, 32, 768)  0           concatenate_1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2D)  (None, 16, 16, 768)  0           leaky_re_lu_8[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_10 (SeparableC (None, 16, 16, 512)  400128      max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_10 (Batc (None, 16, 16, 512)  2048        separable_conv2d_10[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_9 (LeakyReLU)       (None, 16, 16, 512)  0           batch_normalization_v1_10[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_11 (SeparableC (None, 16, 16, 1024) 528896      leaky_re_lu_9[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_11 (Batc (None, 16, 16, 1024) 4096        separable_conv2d_11[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_10 (LeakyReLU)      (None, 16, 16, 1024) 0           batch_normalization_v1_11[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_12 (SeparableC (None, 16, 16, 256)  271360      leaky_re_lu_10[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_9 (SeparableCo (None, 32, 32, 1024) 528896      max_pooling2d[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_12 (Batc (None, 16, 16, 256)  1024        separable_conv2d_12[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_9 (Batch (None, 32, 32, 1024) 4096        separable_conv2d_9[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_2 (Concatenate)     (None, 16, 16, 1024) 0           batch_normalization_v1_12[0][0]  \n",
            "                                                                 max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2D)  (None, 16, 16, 1024) 0           batch_normalization_v1_9[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_3 (Concatenate)     (None, 16, 16, 2048) 0           concatenate_2[0][0]              \n",
            "                                                                 max_pooling2d_2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_11 (LeakyReLU)      (None, 16, 16, 2048) 0           concatenate_3[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d (Conv2D)                 (None, 16, 16, 200)  409600      leaky_re_lu_11[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "global_average_pooling2d (Globa (None, 200)          0           conv2d[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation (Activation)         (None, 200)          0           global_average_pooling2d[0][0]   \n",
            "==================================================================================================\n",
            "Total params: 4,209,819\n",
            "Trainable params: 4,196,123\n",
            "Non-trainable params: 13,696\n",
            "__________________________________________________________________________________________________\n",
            "Found 100000 images belonging to 200 classes.\n",
            "Found 10000 images belonging to 200 classes.\n",
            "Epoch 251/300\n",
            "INFO:tensorflow:New input shapes; (re-)compiling: mode=train (# of cores 8), [TensorSpec(shape=(64,), dtype=tf.int32, name='core_id0'), TensorSpec(shape=(64, 64, 64, 3), dtype=tf.float32, name='input_1_10'), TensorSpec(shape=(64, 200), dtype=tf.float32, name='activation_target_30')]\n",
            "INFO:tensorflow:Overriding default placeholder.\n",
            "INFO:tensorflow:Remapping placeholder for input_1\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/tpu/python/tpu/keras_support.py:302: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "INFO:tensorflow:Started compiling\n",
            "INFO:tensorflow:Finished compiling. Time elapsed: 32.33615303039551 secs\n",
            "INFO:tensorflow:Setting weights on TPU model.\n",
            "194/195 [============================>.] - ETA: 2s - loss: 1.4822 - acc: 0.6313INFO:tensorflow:New input shapes; (re-)compiling: mode=eval (# of cores 8), [TensorSpec(shape=(64,), dtype=tf.int32, name='core_id_10'), TensorSpec(shape=(64, 64, 64, 3), dtype=tf.float32, name='input_1_10'), TensorSpec(shape=(64, 200), dtype=tf.float32, name='activation_target_30')]\n",
            "INFO:tensorflow:Overriding default placeholder.\n",
            "INFO:tensorflow:Remapping placeholder for input_1\n",
            "INFO:tensorflow:Started compiling\n",
            "INFO:tensorflow:Finished compiling. Time elapsed: 5.907095432281494 secs\n",
            "19/20 [===========================>..] - ETA: 0s - loss: 1.9744 - acc: 0.5539INFO:tensorflow:New input shapes; (re-)compiling: mode=eval (# of cores 8), [TensorSpec(shape=(34,), dtype=tf.int32, name='core_id_10'), TensorSpec(shape=(34, 64, 64, 3), dtype=tf.float32, name='input_1_10'), TensorSpec(shape=(34, 200), dtype=tf.float32, name='activation_target_30')]\n",
            "INFO:tensorflow:Overriding default placeholder.\n",
            "INFO:tensorflow:Remapping placeholder for input_1\n",
            "INFO:tensorflow:Started compiling\n",
            "INFO:tensorflow:Finished compiling. Time elapsed: 6.044916152954102 secs\n",
            "20/20 [==============================] - 23s 1s/step - loss: 1.9789 - acc: 0.5537\n",
            "INFO:tensorflow:Copying TPU weights to the CPU\n",
            "195/195 [==============================] - 510s 3s/step - loss: 1.4819 - acc: 0.6314 - val_loss: 1.9789 - val_acc: 0.5537\n",
            "Epoch 252/300\n",
            "INFO:tensorflow:New input shapes; (re-)compiling: mode=train (# of cores 8), [TensorSpec(shape=(20,), dtype=tf.int32, name='core_id0'), TensorSpec(shape=(20, 64, 64, 3), dtype=tf.float32, name='input_1_10'), TensorSpec(shape=(20, 200), dtype=tf.float32, name='activation_target_30')]\n",
            "INFO:tensorflow:Overriding default placeholder.\n",
            "INFO:tensorflow:Remapping placeholder for input_1\n",
            "INFO:tensorflow:Started compiling\n",
            "INFO:tensorflow:Finished compiling. Time elapsed: 26.364964485168457 secs\n",
            "20/20 [==============================] - 14s 687ms/step - loss: 1.9772 - acc: 0.5545\n",
            "INFO:tensorflow:Copying TPU weights to the CPU\n",
            "195/195 [==============================] - 438s 2s/step - loss: 1.4756 - acc: 0.6311 - val_loss: 1.9772 - val_acc: 0.5545\n",
            "Epoch 253/300\n",
            "20/20 [==============================] - 14s 701ms/step - loss: 1.9665 - acc: 0.5544\n",
            "INFO:tensorflow:Copying TPU weights to the CPU\n",
            "195/195 [==============================] - 420s 2s/step - loss: 1.4664 - acc: 0.6350 - val_loss: 1.9665 - val_acc: 0.5544\n",
            "Epoch 254/300\n",
            "20/20 [==============================] - 14s 701ms/step - loss: 1.9903 - acc: 0.5542\n",
            "195/195 [==============================] - 417s 2s/step - loss: 1.5111 - acc: 0.6222 - val_loss: 1.9903 - val_acc: 0.5542\n",
            "Epoch 255/300\n",
            "20/20 [==============================] - 14s 683ms/step - loss: 1.9783 - acc: 0.5539\n",
            "195/195 [==============================] - 421s 2s/step - loss: 1.4857 - acc: 0.6289 - val_loss: 1.9783 - val_acc: 0.5539\n",
            "Epoch 256/300\n",
            "20/20 [==============================] - 14s 676ms/step - loss: 1.9854 - acc: 0.5530\n",
            "195/195 [==============================] - 423s 2s/step - loss: 1.4750 - acc: 0.6310 - val_loss: 1.9854 - val_acc: 0.5530\n",
            "Epoch 257/300\n",
            "20/20 [==============================] - 13s 654ms/step - loss: 1.9651 - acc: 0.5581\n",
            "INFO:tensorflow:Copying TPU weights to the CPU\n",
            "195/195 [==============================] - 424s 2s/step - loss: 1.4707 - acc: 0.6335 - val_loss: 1.9651 - val_acc: 0.5581\n",
            "Epoch 258/300\n",
            "20/20 [==============================] - 14s 688ms/step - loss: 1.9796 - acc: 0.5554\n",
            "195/195 [==============================] - 415s 2s/step - loss: 1.4702 - acc: 0.6336 - val_loss: 1.9796 - val_acc: 0.5554\n",
            "Epoch 259/300\n",
            "20/20 [==============================] - 13s 662ms/step - loss: 1.9811 - acc: 0.5543\n",
            "195/195 [==============================] - 416s 2s/step - loss: 1.4613 - acc: 0.6352 - val_loss: 1.9811 - val_acc: 0.5543\n",
            "Epoch 260/300\n",
            "20/20 [==============================] - 14s 680ms/step - loss: 1.9682 - acc: 0.5574\n",
            "195/195 [==============================] - 424s 2s/step - loss: 1.4592 - acc: 0.6365 - val_loss: 1.9682 - val_acc: 0.5574\n",
            "Epoch 261/300\n",
            "20/20 [==============================] - 13s 670ms/step - loss: 1.9973 - acc: 0.5547\n",
            "195/195 [==============================] - 422s 2s/step - loss: 1.4431 - acc: 0.6388 - val_loss: 1.9973 - val_acc: 0.5547\n",
            "Epoch 262/300\n",
            "20/20 [==============================] - 13s 664ms/step - loss: 1.9730 - acc: 0.5533\n",
            "195/195 [==============================] - 419s 2s/step - loss: 1.4441 - acc: 0.6376 - val_loss: 1.9730 - val_acc: 0.5533\n",
            "Epoch 263/300\n",
            "20/20 [==============================] - 13s 660ms/step - loss: 1.9904 - acc: 0.5559\n",
            "195/195 [==============================] - 420s 2s/step - loss: 1.4433 - acc: 0.6399 - val_loss: 1.9904 - val_acc: 0.5559\n",
            "Epoch 264/300\n",
            "20/20 [==============================] - 13s 658ms/step - loss: 1.9980 - acc: 0.5555\n",
            "195/195 [==============================] - 418s 2s/step - loss: 1.4311 - acc: 0.6396 - val_loss: 1.9980 - val_acc: 0.5555\n",
            "Epoch 265/300\n",
            "20/20 [==============================] - 13s 649ms/step - loss: 1.9899 - acc: 0.5616\n",
            "195/195 [==============================] - 413s 2s/step - loss: 1.4302 - acc: 0.6428 - val_loss: 1.9899 - val_acc: 0.5616\n",
            "Epoch 266/300\n",
            "20/20 [==============================] - 13s 674ms/step - loss: 1.9974 - acc: 0.5565\n",
            "195/195 [==============================] - 416s 2s/step - loss: 1.4247 - acc: 0.6419 - val_loss: 1.9974 - val_acc: 0.5565\n",
            "Epoch 267/300\n",
            "20/20 [==============================] - 12s 606ms/step - loss: 1.9975 - acc: 0.5559\n",
            "195/195 [==============================] - 401s 2s/step - loss: 1.4254 - acc: 0.6431 - val_loss: 1.9975 - val_acc: 0.5559\n",
            "Epoch 268/300\n",
            "20/20 [==============================] - 13s 646ms/step - loss: 2.0011 - acc: 0.5557\n",
            "195/195 [==============================] - 395s 2s/step - loss: 1.4685 - acc: 0.6293 - val_loss: 2.0011 - val_acc: 0.5557\n",
            "Epoch 269/300\n",
            "20/20 [==============================] - 13s 630ms/step - loss: 1.9987 - acc: 0.5555\n",
            "195/195 [==============================] - 410s 2s/step - loss: 1.4583 - acc: 0.6329 - val_loss: 1.9987 - val_acc: 0.5555\n",
            "Epoch 270/300\n",
            "20/20 [==============================] - 13s 643ms/step - loss: 2.0046 - acc: 0.5574\n",
            "195/195 [==============================] - 410s 2s/step - loss: 1.4573 - acc: 0.6333 - val_loss: 2.0046 - val_acc: 0.5574\n",
            "Epoch 271/300\n",
            "20/20 [==============================] - 13s 666ms/step - loss: 2.0087 - acc: 0.5543\n",
            "195/195 [==============================] - 413s 2s/step - loss: 1.4550 - acc: 0.6322 - val_loss: 2.0087 - val_acc: 0.5543\n",
            "Epoch 272/300\n",
            "20/20 [==============================] - 13s 653ms/step - loss: 2.0084 - acc: 0.5565\n",
            "195/195 [==============================] - 417s 2s/step - loss: 1.4495 - acc: 0.6350 - val_loss: 2.0084 - val_acc: 0.5565\n",
            "Epoch 273/300\n",
            "20/20 [==============================] - 13s 667ms/step - loss: 2.0108 - acc: 0.5538\n",
            "195/195 [==============================] - 416s 2s/step - loss: 1.4477 - acc: 0.6347 - val_loss: 2.0108 - val_acc: 0.5538\n",
            "Epoch 274/300\n",
            "20/20 [==============================] - 13s 659ms/step - loss: 2.0148 - acc: 0.5539\n",
            "195/195 [==============================] - 414s 2s/step - loss: 1.4466 - acc: 0.6359 - val_loss: 2.0148 - val_acc: 0.5539\n",
            "Epoch 275/300\n",
            "20/20 [==============================] - 13s 659ms/step - loss: 2.0076 - acc: 0.5536\n",
            "195/195 [==============================] - 417s 2s/step - loss: 1.4448 - acc: 0.6360 - val_loss: 2.0076 - val_acc: 0.5536\n",
            "Epoch 276/300\n",
            "20/20 [==============================] - 13s 660ms/step - loss: 2.0261 - acc: 0.5531\n",
            "195/195 [==============================] - 415s 2s/step - loss: 1.4326 - acc: 0.6396 - val_loss: 2.0261 - val_acc: 0.5531\n",
            "Epoch 277/300\n",
            "20/20 [==============================] - 13s 640ms/step - loss: 2.0246 - acc: 0.5553\n",
            "195/195 [==============================] - 414s 2s/step - loss: 1.4457 - acc: 0.6373 - val_loss: 2.0246 - val_acc: 0.5553\n",
            "Epoch 278/300\n",
            "20/20 [==============================] - 13s 646ms/step - loss: 2.0221 - acc: 0.5567\n",
            "195/195 [==============================] - 413s 2s/step - loss: 1.4326 - acc: 0.6382 - val_loss: 2.0221 - val_acc: 0.5567\n",
            "Epoch 279/300\n",
            "20/20 [==============================] - 13s 648ms/step - loss: 2.0036 - acc: 0.5593\n",
            "195/195 [==============================] - 414s 2s/step - loss: 1.4281 - acc: 0.6379 - val_loss: 2.0036 - val_acc: 0.5593\n",
            "Epoch 280/300\n",
            "20/20 [==============================] - 13s 658ms/step - loss: 2.0303 - acc: 0.5534\n",
            "195/195 [==============================] - 414s 2s/step - loss: 1.4261 - acc: 0.6399 - val_loss: 2.0303 - val_acc: 0.5534\n",
            "Epoch 281/300\n",
            "20/20 [==============================] - 13s 648ms/step - loss: 2.0245 - acc: 0.5546\n",
            "195/195 [==============================] - 414s 2s/step - loss: 1.4305 - acc: 0.6394 - val_loss: 2.0245 - val_acc: 0.5546\n",
            "Epoch 282/300\n",
            "20/20 [==============================] - 13s 654ms/step - loss: 1.9984 - acc: 0.5559\n",
            "195/195 [==============================] - 411s 2s/step - loss: 1.4256 - acc: 0.6409 - val_loss: 1.9984 - val_acc: 0.5559\n",
            "Epoch 283/300\n",
            "20/20 [==============================] - 13s 656ms/step - loss: 2.0131 - acc: 0.5587\n",
            "195/195 [==============================] - 418s 2s/step - loss: 1.4192 - acc: 0.6411 - val_loss: 2.0131 - val_acc: 0.5587\n",
            "Epoch 284/300\n",
            "20/20 [==============================] - 13s 662ms/step - loss: 2.0058 - acc: 0.5565\n",
            "195/195 [==============================] - 417s 2s/step - loss: 1.4141 - acc: 0.6425 - val_loss: 2.0058 - val_acc: 0.5565\n",
            "Epoch 285/300\n",
            "20/20 [==============================] - 13s 673ms/step - loss: 2.0589 - acc: 0.5493\n",
            "195/195 [==============================] - 421s 2s/step - loss: 1.4105 - acc: 0.6441 - val_loss: 2.0589 - val_acc: 0.5493\n",
            "Epoch 286/300\n",
            "20/20 [==============================] - 13s 635ms/step - loss: 2.0415 - acc: 0.5536\n",
            "195/195 [==============================] - 413s 2s/step - loss: 1.4156 - acc: 0.6417 - val_loss: 2.0415 - val_acc: 0.5536\n",
            "Epoch 287/300\n",
            "20/20 [==============================] - 13s 644ms/step - loss: 2.0016 - acc: 0.5568\n",
            "195/195 [==============================] - 412s 2s/step - loss: 1.4186 - acc: 0.6420 - val_loss: 2.0016 - val_acc: 0.5568\n",
            "Epoch 288/300\n",
            "20/20 [==============================] - 13s 650ms/step - loss: 1.9924 - acc: 0.5603\n",
            "195/195 [==============================] - 411s 2s/step - loss: 1.4034 - acc: 0.6444 - val_loss: 1.9924 - val_acc: 0.5603\n",
            "Epoch 289/300\n",
            "20/20 [==============================] - 13s 646ms/step - loss: 2.0371 - acc: 0.5557\n",
            "195/195 [==============================] - 412s 2s/step - loss: 1.3978 - acc: 0.6457 - val_loss: 2.0371 - val_acc: 0.5557\n",
            "Epoch 290/300\n",
            "20/20 [==============================] - 13s 658ms/step - loss: 2.0365 - acc: 0.5530\n",
            "195/195 [==============================] - 411s 2s/step - loss: 1.4028 - acc: 0.6442 - val_loss: 2.0365 - val_acc: 0.5530\n",
            "Epoch 291/300\n",
            "20/20 [==============================] - 13s 647ms/step - loss: 2.0156 - acc: 0.5582\n",
            "195/195 [==============================] - 410s 2s/step - loss: 1.3943 - acc: 0.6472 - val_loss: 2.0156 - val_acc: 0.5582\n",
            "Epoch 292/300\n",
            "20/20 [==============================] - 13s 635ms/step - loss: 2.0493 - acc: 0.5530\n",
            "195/195 [==============================] - 412s 2s/step - loss: 1.4010 - acc: 0.6450 - val_loss: 2.0493 - val_acc: 0.5530\n",
            "Epoch 293/300\n",
            "20/20 [==============================] - 13s 644ms/step - loss: 2.0357 - acc: 0.5541\n",
            "195/195 [==============================] - 410s 2s/step - loss: 1.3868 - acc: 0.6484 - val_loss: 2.0357 - val_acc: 0.5541\n",
            "Epoch 294/300\n",
            "20/20 [==============================] - 13s 643ms/step - loss: 2.0396 - acc: 0.5555\n",
            "195/195 [==============================] - 410s 2s/step - loss: 1.3936 - acc: 0.6474 - val_loss: 2.0396 - val_acc: 0.5555\n",
            "Epoch 295/300\n",
            "20/20 [==============================] - 15s 775ms/step - loss: 2.0294 - acc: 0.5547\n",
            "195/195 [==============================] - 414s 2s/step - loss: 1.3870 - acc: 0.6485 - val_loss: 2.0294 - val_acc: 0.5547\n",
            "Epoch 296/300\n",
            "20/20 [==============================] - 13s 650ms/step - loss: 2.0393 - acc: 0.5539\n",
            "195/195 [==============================] - 414s 2s/step - loss: 1.3926 - acc: 0.6470 - val_loss: 2.0393 - val_acc: 0.5539\n",
            "Epoch 297/300\n",
            "20/20 [==============================] - 13s 649ms/step - loss: 2.0393 - acc: 0.5555\n",
            "195/195 [==============================] - 418s 2s/step - loss: 1.3787 - acc: 0.6498 - val_loss: 2.0393 - val_acc: 0.5555\n",
            "Epoch 298/300\n",
            "20/20 [==============================] - 13s 656ms/step - loss: 2.0486 - acc: 0.5554\n",
            "195/195 [==============================] - 415s 2s/step - loss: 1.3749 - acc: 0.6504 - val_loss: 2.0486 - val_acc: 0.5554\n",
            "Epoch 299/300\n",
            "20/20 [==============================] - 13s 652ms/step - loss: 2.0576 - acc: 0.5528\n",
            "195/195 [==============================] - 416s 2s/step - loss: 1.3730 - acc: 0.6516 - val_loss: 2.0576 - val_acc: 0.5528\n",
            "Epoch 300/300\n",
            "20/20 [==============================] - 13s 647ms/step - loss: 2.0428 - acc: 0.5558\n",
            "195/195 [==============================] - 413s 2s/step - loss: 1.3743 - acc: 0.6500 - val_loss: 2.0428 - val_acc: 0.5558\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FUixpj6X1JWV",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 3930
        },
        "outputId": "a7321aec-aef3-44fd-db5b-8604f957a15b"
      },
      "source": [
        "learning_strategy(image_size=64,previous_epoch=300,epoch_size=325,batchsize=512,learning_rate=0.00006)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading previous model with least val loss: /gdrive/My Drive/tpuweights/vddddAssignment4Amodel_203_1.96.hdf5\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n",
            "\n",
            "WARNING: The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
            "For more information, please see:\n",
            "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
            "  * https://github.com/tensorflow/addons\n",
            "If you depend on functionality not listed there, please file an issue.\n",
            "\n",
            "INFO:tensorflow:Querying Tensorflow master (grpc://10.22.123.178:8470) for TPU system metadata.\n",
            "INFO:tensorflow:Found TPU system:\n",
            "INFO:tensorflow:*** Num TPU Cores: 8\n",
            "INFO:tensorflow:*** Num TPU Workers: 1\n",
            "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, -1, 17802238759688487900)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 17179869184, 2403919027554651168)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 17179869184, 799672640941346087)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 17179869184, 12609454898554945492)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 17179869184, 5978188044300714671)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 17179869184, 8644345904428922285)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 17179869184, 6470482881769532374)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 17179869184, 3899586560819514248)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 17179869184, 14163831283719780045)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 17179869184, 12156992959061376355)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 17179869184, 15242317637018098387)\n",
            "WARNING:tensorflow:tpu_model (from tensorflow.contrib.tpu.python.tpu.keras_support) is experimental and may change or be removed at any time, and without warning.\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            (None, 64, 64, 3)    0                                            \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d (SeparableConv (None, 64, 64, 64)   219         input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1 (BatchNo (None, 64, 64, 64)   256         separable_conv2d[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu (LeakyReLU)         (None, 64, 64, 64)   0           batch_normalization_v1[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_1 (SeparableCo (None, 64, 64, 128)  8768        leaky_re_lu[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_1 (Batch (None, 64, 64, 128)  512         separable_conv2d_1[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_1 (LeakyReLU)       (None, 64, 64, 128)  0           batch_normalization_v1_1[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_2 (SeparableCo (None, 64, 64, 256)  33920       leaky_re_lu_1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_2 (Batch (None, 64, 64, 256)  1024        separable_conv2d_2[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_2 (LeakyReLU)       (None, 64, 64, 256)  0           batch_normalization_v1_2[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_3 (SeparableCo (None, 64, 64, 512)  133376      leaky_re_lu_2[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_3 (Batch (None, 64, 64, 512)  2048        separable_conv2d_3[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_3 (LeakyReLU)       (None, 64, 64, 512)  0           batch_normalization_v1_3[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_4 (SeparableCo (None, 64, 64, 1024) 528896      leaky_re_lu_3[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_4 (Batch (None, 64, 64, 1024) 4096        separable_conv2d_4[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_4 (LeakyReLU)       (None, 64, 64, 1024) 0           batch_normalization_v1_4[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_5 (SeparableCo (None, 64, 64, 256)  271360      leaky_re_lu_4[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_5 (Batch (None, 64, 64, 256)  1024        separable_conv2d_5[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "concatenate (Concatenate)       (None, 64, 64, 512)  0           batch_normalization_v1_5[0][0]   \n",
            "                                                                 leaky_re_lu_2[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_5 (LeakyReLU)       (None, 64, 64, 512)  0           concatenate[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D)    (None, 32, 32, 512)  0           leaky_re_lu_5[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_6 (SeparableCo (None, 32, 32, 512)  266752      max_pooling2d[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_6 (Batch (None, 32, 32, 512)  2048        separable_conv2d_6[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_6 (LeakyReLU)       (None, 32, 32, 512)  0           batch_normalization_v1_6[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_7 (SeparableCo (None, 32, 32, 1024) 528896      leaky_re_lu_6[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_7 (Batch (None, 32, 32, 1024) 4096        separable_conv2d_7[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_7 (LeakyReLU)       (None, 32, 32, 1024) 0           batch_normalization_v1_7[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_8 (SeparableCo (None, 32, 32, 256)  271360      leaky_re_lu_7[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_8 (Batch (None, 32, 32, 256)  1024        separable_conv2d_8[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_1 (Concatenate)     (None, 32, 32, 768)  0           batch_normalization_v1_8[0][0]   \n",
            "                                                                 max_pooling2d[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_8 (LeakyReLU)       (None, 32, 32, 768)  0           concatenate_1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2D)  (None, 16, 16, 768)  0           leaky_re_lu_8[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_10 (SeparableC (None, 16, 16, 512)  400128      max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_10 (Batc (None, 16, 16, 512)  2048        separable_conv2d_10[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_9 (LeakyReLU)       (None, 16, 16, 512)  0           batch_normalization_v1_10[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_11 (SeparableC (None, 16, 16, 1024) 528896      leaky_re_lu_9[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_11 (Batc (None, 16, 16, 1024) 4096        separable_conv2d_11[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_10 (LeakyReLU)      (None, 16, 16, 1024) 0           batch_normalization_v1_11[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_12 (SeparableC (None, 16, 16, 256)  271360      leaky_re_lu_10[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_9 (SeparableCo (None, 32, 32, 1024) 528896      max_pooling2d[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_12 (Batc (None, 16, 16, 256)  1024        separable_conv2d_12[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_9 (Batch (None, 32, 32, 1024) 4096        separable_conv2d_9[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_2 (Concatenate)     (None, 16, 16, 1024) 0           batch_normalization_v1_12[0][0]  \n",
            "                                                                 max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2D)  (None, 16, 16, 1024) 0           batch_normalization_v1_9[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_3 (Concatenate)     (None, 16, 16, 2048) 0           concatenate_2[0][0]              \n",
            "                                                                 max_pooling2d_2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_11 (LeakyReLU)      (None, 16, 16, 2048) 0           concatenate_3[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d (Conv2D)                 (None, 16, 16, 200)  409600      leaky_re_lu_11[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "global_average_pooling2d (Globa (None, 200)          0           conv2d[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation (Activation)         (None, 200)          0           global_average_pooling2d[0][0]   \n",
            "==================================================================================================\n",
            "Total params: 4,209,819\n",
            "Trainable params: 4,196,123\n",
            "Non-trainable params: 13,696\n",
            "__________________________________________________________________________________________________\n",
            "Found 100000 images belonging to 200 classes.\n",
            "Found 10000 images belonging to 200 classes.\n",
            "Epoch 301/325\n",
            "INFO:tensorflow:New input shapes; (re-)compiling: mode=train (# of cores 8), [TensorSpec(shape=(64,), dtype=tf.int32, name='core_id0'), TensorSpec(shape=(64, 64, 64, 3), dtype=tf.float32, name='input_1_10'), TensorSpec(shape=(64, 200), dtype=tf.float32, name='activation_target_30')]\n",
            "INFO:tensorflow:Overriding default placeholder.\n",
            "INFO:tensorflow:Remapping placeholder for input_1\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/tpu/python/tpu/keras_support.py:302: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "INFO:tensorflow:Started compiling\n",
            "INFO:tensorflow:Finished compiling. Time elapsed: 32.186744928359985 secs\n",
            "INFO:tensorflow:Setting weights on TPU model.\n",
            "194/195 [============================>.] - ETA: 2s - loss: 1.4867 - acc: 0.6293INFO:tensorflow:New input shapes; (re-)compiling: mode=eval (# of cores 8), [TensorSpec(shape=(64,), dtype=tf.int32, name='core_id_10'), TensorSpec(shape=(64, 64, 64, 3), dtype=tf.float32, name='input_1_10'), TensorSpec(shape=(64, 200), dtype=tf.float32, name='activation_target_30')]\n",
            "INFO:tensorflow:Overriding default placeholder.\n",
            "INFO:tensorflow:Remapping placeholder for input_1\n",
            "INFO:tensorflow:Started compiling\n",
            "INFO:tensorflow:Finished compiling. Time elapsed: 5.945069789886475 secs\n",
            "19/20 [===========================>..] - ETA: 0s - loss: 1.9655 - acc: 0.5547INFO:tensorflow:New input shapes; (re-)compiling: mode=eval (# of cores 8), [TensorSpec(shape=(34,), dtype=tf.int32, name='core_id_10'), TensorSpec(shape=(34, 64, 64, 3), dtype=tf.float32, name='input_1_10'), TensorSpec(shape=(34, 200), dtype=tf.float32, name='activation_target_30')]\n",
            "INFO:tensorflow:Overriding default placeholder.\n",
            "INFO:tensorflow:Remapping placeholder for input_1\n",
            "INFO:tensorflow:Started compiling\n",
            "INFO:tensorflow:Finished compiling. Time elapsed: 6.301683664321899 secs\n",
            "20/20 [==============================] - 23s 1s/step - loss: 1.9702 - acc: 0.5548\n",
            "INFO:tensorflow:Copying TPU weights to the CPU\n",
            "195/195 [==============================] - 491s 3s/step - loss: 1.4862 - acc: 0.6294 - val_loss: 1.9702 - val_acc: 0.5548\n",
            "Epoch 302/325\n",
            "INFO:tensorflow:New input shapes; (re-)compiling: mode=train (# of cores 8), [TensorSpec(shape=(20,), dtype=tf.int32, name='core_id0'), TensorSpec(shape=(20, 64, 64, 3), dtype=tf.float32, name='input_1_10'), TensorSpec(shape=(20, 200), dtype=tf.float32, name='activation_target_30')]\n",
            "INFO:tensorflow:Overriding default placeholder.\n",
            "INFO:tensorflow:Remapping placeholder for input_1\n",
            "INFO:tensorflow:Started compiling\n",
            "INFO:tensorflow:Finished compiling. Time elapsed: 26.0634765625 secs\n",
            "20/20 [==============================] - 13s 664ms/step - loss: 1.9638 - acc: 0.5539\n",
            "195/195 [==============================] - 439s 2s/step - loss: 1.4739 - acc: 0.6309 - val_loss: 1.9638 - val_acc: 0.5539\n",
            "Epoch 303/325\n",
            "20/20 [==============================] - 14s 690ms/step - loss: 1.9526 - acc: 0.5546\n",
            "195/195 [==============================] - 427s 2s/step - loss: 1.4652 - acc: 0.6347 - val_loss: 1.9526 - val_acc: 0.5546\n",
            "Epoch 304/325\n",
            "20/20 [==============================] - 14s 700ms/step - loss: 1.9648 - acc: 0.5557\n",
            "INFO:tensorflow:Copying TPU weights to the CPU\n",
            "195/195 [==============================] - 430s 2s/step - loss: 1.5111 - acc: 0.6211 - val_loss: 1.9648 - val_acc: 0.5557\n",
            "Epoch 305/325\n",
            "20/20 [==============================] - 14s 691ms/step - loss: 1.9638 - acc: 0.5579\n",
            "INFO:tensorflow:Copying TPU weights to the CPU\n",
            "195/195 [==============================] - 428s 2s/step - loss: 1.4866 - acc: 0.6281 - val_loss: 1.9638 - val_acc: 0.5579\n",
            "Epoch 306/325\n",
            "20/20 [==============================] - 13s 671ms/step - loss: 1.9920 - acc: 0.5515\n",
            "195/195 [==============================] - 422s 2s/step - loss: 1.4790 - acc: 0.6298 - val_loss: 1.9920 - val_acc: 0.5515\n",
            "Epoch 307/325\n",
            "20/20 [==============================] - 13s 668ms/step - loss: 1.9774 - acc: 0.5559\n",
            "195/195 [==============================] - 426s 2s/step - loss: 1.4727 - acc: 0.6322 - val_loss: 1.9774 - val_acc: 0.5559\n",
            "Epoch 308/325\n",
            "20/20 [==============================] - 14s 687ms/step - loss: 1.9570 - acc: 0.5562\n",
            "195/195 [==============================] - 428s 2s/step - loss: 1.4682 - acc: 0.6324 - val_loss: 1.9570 - val_acc: 0.5562\n",
            "Epoch 309/325\n",
            "20/20 [==============================] - 14s 701ms/step - loss: 1.9819 - acc: 0.5536\n",
            "195/195 [==============================] - 425s 2s/step - loss: 1.4604 - acc: 0.6358 - val_loss: 1.9819 - val_acc: 0.5536\n",
            "Epoch 310/325\n",
            "20/20 [==============================] - 13s 674ms/step - loss: 1.9784 - acc: 0.5577\n",
            "195/195 [==============================] - 426s 2s/step - loss: 1.4572 - acc: 0.6360 - val_loss: 1.9784 - val_acc: 0.5577\n",
            "Epoch 311/325\n",
            "20/20 [==============================] - 14s 682ms/step - loss: 2.0048 - acc: 0.5531\n",
            "195/195 [==============================] - 424s 2s/step - loss: 1.4437 - acc: 0.6373 - val_loss: 2.0048 - val_acc: 0.5531\n",
            "Epoch 312/325\n",
            "20/20 [==============================] - 14s 679ms/step - loss: 1.9816 - acc: 0.5550\n",
            "195/195 [==============================] - 425s 2s/step - loss: 1.4442 - acc: 0.6378 - val_loss: 1.9816 - val_acc: 0.5550\n",
            "Epoch 313/325\n",
            "20/20 [==============================] - 14s 683ms/step - loss: 1.9733 - acc: 0.5559\n",
            "195/195 [==============================] - 427s 2s/step - loss: 1.4383 - acc: 0.6400 - val_loss: 1.9733 - val_acc: 0.5559\n",
            "Epoch 314/325\n",
            "20/20 [==============================] - 14s 681ms/step - loss: 1.9801 - acc: 0.5564\n",
            "195/195 [==============================] - 425s 2s/step - loss: 1.4287 - acc: 0.6402 - val_loss: 1.9801 - val_acc: 0.5564\n",
            "Epoch 315/325\n",
            "20/20 [==============================] - 14s 703ms/step - loss: 1.9988 - acc: 0.5555\n",
            "195/195 [==============================] - 425s 2s/step - loss: 1.4303 - acc: 0.6412 - val_loss: 1.9988 - val_acc: 0.5555\n",
            "Epoch 316/325\n",
            "20/20 [==============================] - 14s 683ms/step - loss: 1.9676 - acc: 0.5568\n",
            "195/195 [==============================] - 428s 2s/step - loss: 1.4265 - acc: 0.6404 - val_loss: 1.9676 - val_acc: 0.5568\n",
            "Epoch 317/325\n",
            " 12/195 [>.............................] - ETA: 4:33 - loss: 1.4793 - acc: 0.6214"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nkIfQSdqVugJ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 659
        },
        "outputId": "d7725f7b-4d41-4f40-8d31-83bb05e20480"
      },
      "source": [
        "tf.keras.backend.clear_session()\n",
        "TPU_WORKER = 'grpc://' + os.environ['COLAB_TPU_ADDR']\n",
        "  \n",
        "modelfinal = fetch_model(64)\n",
        "modelfinal.compile(loss='categorical_crossentropy',optimizer=tf.train.AdamOptimizer(learning_rate=0.00006),metrics=['accuracy'])\n",
        "final_model_tpu = tf.contrib.tpu.keras_to_tpu_model(modelfinal,strategy=tf.contrib.tpu.TPUDistributionStrategy(tf.contrib.cluster_resolver.TPUClusterResolver(tpu=TPU_WORKER)))\n",
        "\n",
        "final_validation_generator = valid_datagen.flow_from_dataframe(val_data, directory='./tiny-imagenet-200/val/images/', x_col='File', y_col='Class', target_size=(64,64),\n",
        "                                                    color_mode='rgb', class_mode='categorical', batch_size=512, shuffle=False, seed=42)\n",
        "score = final_model_tpu.evaluate_generator(final_validation_generator)\n",
        "print(final_model_tpu.metrics_names)\n",
        "print(score)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading previous model with least val loss: /gdrive/My Drive/tpuweights/vddddAssignment4Amodel_203_1.96.hdf5\n",
            "INFO:tensorflow:Querying Tensorflow master (grpc://10.19.20.58:8470) for TPU system metadata.\n",
            "INFO:tensorflow:Found TPU system:\n",
            "INFO:tensorflow:*** Num TPU Cores: 8\n",
            "INFO:tensorflow:*** Num TPU Workers: 1\n",
            "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, -1, 3188175346484654332)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 17179869184, 9322828699166116140)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 17179869184, 7441547133411068124)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 17179869184, 16478797923714726733)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 17179869184, 2105291141815206392)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 17179869184, 11233095456885272006)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 17179869184, 6391904787720182526)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 17179869184, 15665763205029971114)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 17179869184, 15028551727319526052)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 17179869184, 58976133908321951)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 17179869184, 12590569351911159793)\n",
            "WARNING:tensorflow:tpu_model (from tensorflow.contrib.tpu.python.tpu.keras_support) is experimental and may change or be removed at any time, and without warning.\n",
            "Found 10000 images belonging to 200 classes.\n",
            "INFO:tensorflow:New input shapes; (re-)compiling: mode=eval (# of cores 8), [TensorSpec(shape=(64,), dtype=tf.int32, name='core_id0'), TensorSpec(shape=(64, 64, 64, 3), dtype=tf.float32, name='input_1_10'), TensorSpec(shape=(64, 200), dtype=tf.float32, name='activation_target_30')]\n",
            "INFO:tensorflow:Overriding default placeholder.\n",
            "INFO:tensorflow:Remapping placeholder for input_1\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/tpu/python/tpu/keras_support.py:302: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "INFO:tensorflow:Started compiling\n",
            "INFO:tensorflow:Finished compiling. Time elapsed: 8.056725263595581 secs\n",
            "INFO:tensorflow:Setting weights on TPU model.\n",
            "INFO:tensorflow:New input shapes; (re-)compiling: mode=eval (# of cores 8), [TensorSpec(shape=(34,), dtype=tf.int32, name='core_id0'), TensorSpec(shape=(34, 64, 64, 3), dtype=tf.float32, name='input_1_10'), TensorSpec(shape=(34, 200), dtype=tf.float32, name='activation_target_30')]\n",
            "INFO:tensorflow:Overriding default placeholder.\n",
            "INFO:tensorflow:Remapping placeholder for input_1\n",
            "INFO:tensorflow:Started compiling\n",
            "INFO:tensorflow:Finished compiling. Time elapsed: 4.637096881866455 secs\n",
            "['loss', 'acc']\n",
            "[1.953713744878769, 0.5534]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "paeGV9c3wQue"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "import random\n",
        "\n",
        "(x_batch,y_batch) = next(train_generator)\n",
        "\n",
        "# Plot Generator images.\n",
        "def plot_object(image):\n",
        "  fig = plt.figure(figsize=(4,4))\n",
        "  plt.imshow(image, interpolation=\"nearest\")\n",
        "  plt.show()\n",
        "\n",
        "for i in range(4):\n",
        "    index = random.randint(1,500)\n",
        "    print(x_batch[index])\n",
        "    plot_object(x_batch[index])\n",
        "    print(adaptive_equalisation(x_batch[index]))\n",
        "    plot_object(adaptive_equalisation(x_batch[index]))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}